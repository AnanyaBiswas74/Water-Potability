{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6beb6b0e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-29T12:10:28.987063Z",
     "start_time": "2023-01-29T12:10:28.978800Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV, GridSearchCV\n",
    "from sklearn.metrics import classification_report,accuracy_score,confusion_matrix,roc_auc_score,roc_curve\n",
    "from sklearn.tree import  DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_selection import RFE\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import KFold,cross_val_score\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e3da0149",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-29T07:13:54.272901Z",
     "start_time": "2023-01-29T07:13:54.239206Z"
    }
   },
   "outputs": [],
   "source": [
    "water = pd.read_csv(\"water.csv\", index_col=\"Unnamed: 0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e84cbfa0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-29T07:13:58.339260Z",
     "start_time": "2023-01-29T07:13:58.297069Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ph</th>\n",
       "      <th>Hardness</th>\n",
       "      <th>Solids</th>\n",
       "      <th>Chloramines</th>\n",
       "      <th>Sulfate</th>\n",
       "      <th>Conductivity</th>\n",
       "      <th>Organic_carbon</th>\n",
       "      <th>Trihalomethanes</th>\n",
       "      <th>Turbidity</th>\n",
       "      <th>Potability</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8.316766</td>\n",
       "      <td>214.373394</td>\n",
       "      <td>22018.417441</td>\n",
       "      <td>8.059332</td>\n",
       "      <td>356.886136</td>\n",
       "      <td>363.266516</td>\n",
       "      <td>18.436524</td>\n",
       "      <td>100.341674</td>\n",
       "      <td>4.628771</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9.092223</td>\n",
       "      <td>181.101509</td>\n",
       "      <td>17978.986339</td>\n",
       "      <td>6.546600</td>\n",
       "      <td>310.135738</td>\n",
       "      <td>398.410813</td>\n",
       "      <td>11.558279</td>\n",
       "      <td>31.997993</td>\n",
       "      <td>4.075075</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5.584087</td>\n",
       "      <td>188.313324</td>\n",
       "      <td>28748.687739</td>\n",
       "      <td>7.544869</td>\n",
       "      <td>326.678363</td>\n",
       "      <td>280.467916</td>\n",
       "      <td>8.399735</td>\n",
       "      <td>54.917862</td>\n",
       "      <td>2.559708</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10.223862</td>\n",
       "      <td>248.071735</td>\n",
       "      <td>28749.716544</td>\n",
       "      <td>7.513408</td>\n",
       "      <td>393.663396</td>\n",
       "      <td>283.651634</td>\n",
       "      <td>13.789695</td>\n",
       "      <td>84.603556</td>\n",
       "      <td>2.672989</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8.635849</td>\n",
       "      <td>203.361523</td>\n",
       "      <td>13672.091764</td>\n",
       "      <td>4.563009</td>\n",
       "      <td>303.309771</td>\n",
       "      <td>474.607645</td>\n",
       "      <td>12.363817</td>\n",
       "      <td>62.798309</td>\n",
       "      <td>4.401425</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2473</th>\n",
       "      <td>4.668102</td>\n",
       "      <td>193.681735</td>\n",
       "      <td>47580.991603</td>\n",
       "      <td>7.166639</td>\n",
       "      <td>359.948574</td>\n",
       "      <td>526.424171</td>\n",
       "      <td>13.894419</td>\n",
       "      <td>66.687695</td>\n",
       "      <td>4.435821</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2474</th>\n",
       "      <td>7.808856</td>\n",
       "      <td>193.553212</td>\n",
       "      <td>17329.802160</td>\n",
       "      <td>8.061362</td>\n",
       "      <td>333.578349</td>\n",
       "      <td>392.449580</td>\n",
       "      <td>19.903225</td>\n",
       "      <td>66.396293</td>\n",
       "      <td>2.798243</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2475</th>\n",
       "      <td>9.419510</td>\n",
       "      <td>175.762646</td>\n",
       "      <td>33155.578218</td>\n",
       "      <td>7.350233</td>\n",
       "      <td>333.578349</td>\n",
       "      <td>432.044783</td>\n",
       "      <td>11.039070</td>\n",
       "      <td>69.845400</td>\n",
       "      <td>3.298875</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2476</th>\n",
       "      <td>5.126763</td>\n",
       "      <td>230.603758</td>\n",
       "      <td>11983.869376</td>\n",
       "      <td>6.303357</td>\n",
       "      <td>333.578349</td>\n",
       "      <td>402.883113</td>\n",
       "      <td>11.168946</td>\n",
       "      <td>77.488213</td>\n",
       "      <td>4.708658</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2477</th>\n",
       "      <td>7.874671</td>\n",
       "      <td>195.102299</td>\n",
       "      <td>17404.177061</td>\n",
       "      <td>7.509306</td>\n",
       "      <td>333.578349</td>\n",
       "      <td>327.459760</td>\n",
       "      <td>16.140368</td>\n",
       "      <td>78.698446</td>\n",
       "      <td>2.309149</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2478 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             ph    Hardness        Solids  Chloramines     Sulfate  \\\n",
       "0      8.316766  214.373394  22018.417441     8.059332  356.886136   \n",
       "1      9.092223  181.101509  17978.986339     6.546600  310.135738   \n",
       "2      5.584087  188.313324  28748.687739     7.544869  326.678363   \n",
       "3     10.223862  248.071735  28749.716544     7.513408  393.663396   \n",
       "4      8.635849  203.361523  13672.091764     4.563009  303.309771   \n",
       "...         ...         ...           ...          ...         ...   \n",
       "2473   4.668102  193.681735  47580.991603     7.166639  359.948574   \n",
       "2474   7.808856  193.553212  17329.802160     8.061362  333.578349   \n",
       "2475   9.419510  175.762646  33155.578218     7.350233  333.578349   \n",
       "2476   5.126763  230.603758  11983.869376     6.303357  333.578349   \n",
       "2477   7.874671  195.102299  17404.177061     7.509306  333.578349   \n",
       "\n",
       "      Conductivity  Organic_carbon  Trihalomethanes  Turbidity  Potability  \n",
       "0       363.266516       18.436524       100.341674   4.628771         0.0  \n",
       "1       398.410813       11.558279        31.997993   4.075075         0.0  \n",
       "2       280.467916        8.399735        54.917862   2.559708         0.0  \n",
       "3       283.651634       13.789695        84.603556   2.672989         0.0  \n",
       "4       474.607645       12.363817        62.798309   4.401425         0.0  \n",
       "...            ...             ...              ...        ...         ...  \n",
       "2473    526.424171       13.894419        66.687695   4.435821         1.0  \n",
       "2474    392.449580       19.903225        66.396293   2.798243         1.0  \n",
       "2475    432.044783       11.039070        69.845400   3.298875         1.0  \n",
       "2476    402.883113       11.168946        77.488213   4.708658         1.0  \n",
       "2477    327.459760       16.140368        78.698446   2.309149         1.0  \n",
       "\n",
       "[2478 rows x 10 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "water"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2efbe018",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-29T07:14:09.499287Z",
     "start_time": "2023-01-29T07:14:09.483715Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0    1278\n",
       "0.0    1200\n",
       "Name: Potability, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "water.Potability.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7c538a3d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ph</th>\n",
       "      <th>Hardness</th>\n",
       "      <th>Solids</th>\n",
       "      <th>Chloramines</th>\n",
       "      <th>Sulfate</th>\n",
       "      <th>Conductivity</th>\n",
       "      <th>Organic_carbon</th>\n",
       "      <th>Trihalomethanes</th>\n",
       "      <th>Turbidity</th>\n",
       "      <th>Potability</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>2478.000000</td>\n",
       "      <td>2478.000000</td>\n",
       "      <td>2478.000000</td>\n",
       "      <td>2478.000000</td>\n",
       "      <td>2478.000000</td>\n",
       "      <td>2478.000000</td>\n",
       "      <td>2478.000000</td>\n",
       "      <td>2478.000000</td>\n",
       "      <td>2478.000000</td>\n",
       "      <td>2478.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>7.070351</td>\n",
       "      <td>195.901323</td>\n",
       "      <td>22018.152811</td>\n",
       "      <td>7.139279</td>\n",
       "      <td>333.256035</td>\n",
       "      <td>426.434910</td>\n",
       "      <td>14.276804</td>\n",
       "      <td>66.410122</td>\n",
       "      <td>3.961962</td>\n",
       "      <td>0.515738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.504529</td>\n",
       "      <td>33.289438</td>\n",
       "      <td>8803.279996</td>\n",
       "      <td>1.597340</td>\n",
       "      <td>39.309140</td>\n",
       "      <td>80.997820</td>\n",
       "      <td>3.317292</td>\n",
       "      <td>15.949891</td>\n",
       "      <td>0.781750</td>\n",
       "      <td>0.499853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.227499</td>\n",
       "      <td>47.432000</td>\n",
       "      <td>320.942611</td>\n",
       "      <td>0.352000</td>\n",
       "      <td>129.000000</td>\n",
       "      <td>201.619737</td>\n",
       "      <td>2.200000</td>\n",
       "      <td>8.175876</td>\n",
       "      <td>1.450000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>6.162214</td>\n",
       "      <td>176.283379</td>\n",
       "      <td>15596.765222</td>\n",
       "      <td>6.126996</td>\n",
       "      <td>311.618643</td>\n",
       "      <td>365.641745</td>\n",
       "      <td>12.065478</td>\n",
       "      <td>56.470637</td>\n",
       "      <td>3.439135</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>7.070351</td>\n",
       "      <td>196.696937</td>\n",
       "      <td>20966.659459</td>\n",
       "      <td>7.153583</td>\n",
       "      <td>333.578349</td>\n",
       "      <td>422.485813</td>\n",
       "      <td>14.229935</td>\n",
       "      <td>66.396293</td>\n",
       "      <td>3.951949</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>7.946553</td>\n",
       "      <td>216.425007</td>\n",
       "      <td>27360.608486</td>\n",
       "      <td>8.135316</td>\n",
       "      <td>355.477181</td>\n",
       "      <td>482.800158</td>\n",
       "      <td>16.562182</td>\n",
       "      <td>77.129153</td>\n",
       "      <td>4.501849</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>14.000000</td>\n",
       "      <td>323.124000</td>\n",
       "      <td>56488.672413</td>\n",
       "      <td>13.127000</td>\n",
       "      <td>481.030642</td>\n",
       "      <td>753.342620</td>\n",
       "      <td>27.006707</td>\n",
       "      <td>124.000000</td>\n",
       "      <td>6.494749</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                ph     Hardness        Solids  Chloramines      Sulfate  \\\n",
       "count  2478.000000  2478.000000   2478.000000  2478.000000  2478.000000   \n",
       "mean      7.070351   195.901323  22018.152811     7.139279   333.256035   \n",
       "std       1.504529    33.289438   8803.279996     1.597340    39.309140   \n",
       "min       0.227499    47.432000    320.942611     0.352000   129.000000   \n",
       "25%       6.162214   176.283379  15596.765222     6.126996   311.618643   \n",
       "50%       7.070351   196.696937  20966.659459     7.153583   333.578349   \n",
       "75%       7.946553   216.425007  27360.608486     8.135316   355.477181   \n",
       "max      14.000000   323.124000  56488.672413    13.127000   481.030642   \n",
       "\n",
       "       Conductivity  Organic_carbon  Trihalomethanes    Turbidity   Potability  \n",
       "count   2478.000000     2478.000000      2478.000000  2478.000000  2478.000000  \n",
       "mean     426.434910       14.276804        66.410122     3.961962     0.515738  \n",
       "std       80.997820        3.317292        15.949891     0.781750     0.499853  \n",
       "min      201.619737        2.200000         8.175876     1.450000     0.000000  \n",
       "25%      365.641745       12.065478        56.470637     3.439135     0.000000  \n",
       "50%      422.485813       14.229935        66.396293     3.951949     1.000000  \n",
       "75%      482.800158       16.562182        77.129153     4.501849     1.000000  \n",
       "max      753.342620       27.006707       124.000000     6.494749     1.000000  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "water.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "aedfcb0f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-29T07:14:42.910441Z",
     "start_time": "2023-01-29T07:14:42.899556Z"
    }
   },
   "outputs": [],
   "source": [
    "X = water.drop(columns=\"Potability\")\n",
    "Y = water.Potability\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, train_size=.80, random_state=42, stratify=Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cfd70787",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-29T07:15:09.545835Z",
     "start_time": "2023-01-29T07:15:09.532707Z"
    }
   },
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a0141565",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-29T07:23:12.001853Z",
     "start_time": "2023-01-29T07:23:11.979998Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logit = LogisticRegression()\n",
    "logit.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a1d2f00f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-29T07:24:51.714601Z",
     "start_time": "2023-01-29T07:24:51.702890Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.5060544904137235, 0.5403225806451613)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logit.score(X_train, Y_train), logit.score(X_test, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1f3f6c01",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-29T07:26:41.316381Z",
     "start_time": "2023-01-29T07:26:41.292958Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 58 182]\n",
      " [ 46 210]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.56      0.24      0.34       240\n",
      "         1.0       0.54      0.82      0.65       256\n",
      "\n",
      "    accuracy                           0.54       496\n",
      "   macro avg       0.55      0.53      0.49       496\n",
      "weighted avg       0.55      0.54      0.50       496\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pred1 = logit.predict(X_train)\n",
    "pred_test1 = logit.predict(X_test)\n",
    "\n",
    "print(confusion_matrix(Y_test, pred_test1))\n",
    "\n",
    "print(classification_report(Y_test, pred_test1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "41599842",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-29T07:38:23.488314Z",
     "start_time": "2023-01-29T07:38:23.466902Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-7 {color: black;background-color: white;}#sk-container-id-7 pre{padding: 0;}#sk-container-id-7 div.sk-toggleable {background-color: white;}#sk-container-id-7 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-7 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-7 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-7 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-7 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-7 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-7 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-7 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-7 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-7 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-7 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-7 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-7 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-7 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-7 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-7 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-7 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-7 div.sk-item {position: relative;z-index: 1;}#sk-container-id-7 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-7 div.sk-item::before, #sk-container-id-7 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-7 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-7 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-7 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-7 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-7 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-7 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-7 div.sk-label-container {text-align: center;}#sk-container-id-7 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-7 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-7\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>DecisionTreeClassifier(max_depth=5)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-7\" type=\"checkbox\" checked><label for=\"sk-estimator-id-7\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">DecisionTreeClassifier</label><div class=\"sk-toggleable__content\"><pre>DecisionTreeClassifier(max_depth=5)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "DecisionTreeClassifier(max_depth=5)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1 = DecisionTreeClassifier(max_depth=5)\n",
    "model1.fit(X_train, Y_train) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "cc860d13",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-29T07:38:25.661035Z",
     "start_time": "2023-01-29T07:38:25.648438Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.7462159434914228, 0.6915322580645161)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1.score(X_train, Y_train), model1.score(X_test, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e5f4d31b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-29T07:44:06.905655Z",
     "start_time": "2023-01-29T07:44:06.886017Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[176  64]\n",
      " [ 89 167]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.66      0.73      0.70       240\n",
      "         1.0       0.72      0.65      0.69       256\n",
      "\n",
      "    accuracy                           0.69       496\n",
      "   macro avg       0.69      0.69      0.69       496\n",
      "weighted avg       0.69      0.69      0.69       496\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pred2 = model1.predict(X_train)\n",
    "pred_test2 = model1.predict(X_test)\n",
    "\n",
    "print(confusion_matrix(Y_test, pred_test2))\n",
    "\n",
    "print(classification_report(Y_test, pred_test2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "7dc6eb97",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-29T08:57:46.393774Z",
     "start_time": "2023-01-29T08:57:46.326756Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0.69269521, 0.65994962, 0.70959596, 0.7020202 , 0.68181818]),\n",
       " 0.017335765679806023,\n",
       " 0.6892158359412768)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k_fold = KFold(n_splits=5, shuffle=True, random_state=123)\n",
    "cvscore_train = cross_val_score(estimator=model1, X=X_train, y=Y_train, cv=k_fold)\n",
    "\n",
    "cvscore_train, cvscore_train.std(), cvscore_train.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "aa8abf48",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-29T08:58:00.322574Z",
     "start_time": "2023-01-29T08:58:00.277201Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0.61      , 0.63636364, 0.65656566, 0.57575758, 0.54545455]),\n",
       " 0.0401704561130716,\n",
       " 0.6048282828282828)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k_fold = KFold(n_splits=5, shuffle=True, random_state=123)\n",
    "cvscore_test = cross_val_score(estimator=model1, X=X_test, y=Y_test, cv=k_fold)\n",
    "\n",
    "cvscore_test, cvscore_test.std(), cvscore_test.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "534ebcc2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-29T09:02:32.092684Z",
     "start_time": "2023-01-29T09:02:13.873740Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/shubhamswarnakar/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:427: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/Users/shubhamswarnakar/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:427: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/Users/shubhamswarnakar/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:427: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/Users/shubhamswarnakar/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:427: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/Users/shubhamswarnakar/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:427: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-8 {color: black;background-color: white;}#sk-container-id-8 pre{padding: 0;}#sk-container-id-8 div.sk-toggleable {background-color: white;}#sk-container-id-8 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-8 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-8 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-8 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-8 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-8 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-8 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-8 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-8 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-8 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-8 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-8 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-8 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-8 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-8 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-8 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-8 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-8 div.sk-item {position: relative;z-index: 1;}#sk-container-id-8 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-8 div.sk-item::before, #sk-container-id-8 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-8 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-8 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-8 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-8 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-8 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-8 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-8 div.sk-label-container {text-align: center;}#sk-container-id-8 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-8 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-8\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomizedSearchCV(cv=5, estimator=RandomForestClassifier(),\n",
       "                   param_distributions=[{&#x27;bootstrap&#x27;: [True, False],\n",
       "                                         &#x27;max_depth&#x27;: [2, 3, 4, 5, 8, 10, 12,\n",
       "                                                       15],\n",
       "                                         &#x27;max_features&#x27;: [&#x27;sqrt&#x27;, &#x27;auto&#x27;,\n",
       "                                                          &#x27;log2&#x27;, 0.2, None],\n",
       "                                         &#x27;n_estimators&#x27;: [10, 25, 50, 75,\n",
       "                                                          100]}],\n",
       "                   scoring=&#x27;neg_mean_squared_error&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-8\" type=\"checkbox\" ><label for=\"sk-estimator-id-8\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomizedSearchCV</label><div class=\"sk-toggleable__content\"><pre>RandomizedSearchCV(cv=5, estimator=RandomForestClassifier(),\n",
       "                   param_distributions=[{&#x27;bootstrap&#x27;: [True, False],\n",
       "                                         &#x27;max_depth&#x27;: [2, 3, 4, 5, 8, 10, 12,\n",
       "                                                       15],\n",
       "                                         &#x27;max_features&#x27;: [&#x27;sqrt&#x27;, &#x27;auto&#x27;,\n",
       "                                                          &#x27;log2&#x27;, 0.2, None],\n",
       "                                         &#x27;n_estimators&#x27;: [10, 25, 50, 75,\n",
       "                                                          100]}],\n",
       "                   scoring=&#x27;neg_mean_squared_error&#x27;)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-9\" type=\"checkbox\" ><label for=\"sk-estimator-id-9\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier()</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-10\" type=\"checkbox\" ><label for=\"sk-estimator-id-10\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier()</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomizedSearchCV(cv=5, estimator=RandomForestClassifier(),\n",
       "                   param_distributions=[{'bootstrap': [True, False],\n",
       "                                         'max_depth': [2, 3, 4, 5, 8, 10, 12,\n",
       "                                                       15],\n",
       "                                         'max_features': ['sqrt', 'auto',\n",
       "                                                          'log2', 0.2, None],\n",
       "                                         'n_estimators': [10, 25, 50, 75,\n",
       "                                                          100]}],\n",
       "                   scoring='neg_mean_squared_error')"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf= RandomForestClassifier()\n",
    "param_grid = [\n",
    "{'n_estimators': [10, 25, 50,75,100], \n",
    " 'max_depth': [2, 3, 4, 5, 8, 10, 12, 15], \n",
    " 'bootstrap': [True, False],\n",
    " 'max_features':[\"sqrt\",\"auto\",\"log2\", 0.2, None]}\n",
    "]\n",
    "\n",
    "random_search = RandomizedSearchCV(rf, param_grid, cv=5, scoring='neg_mean_squared_error')\n",
    "random_search.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "4c512bde",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-29T09:03:09.228448Z",
     "start_time": "2023-01-29T09:03:09.218108Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'n_estimators': 75,\n",
       "  'max_features': 'log2',\n",
       "  'max_depth': 8,\n",
       "  'bootstrap': False},\n",
       " RandomForestClassifier(bootstrap=False, max_depth=8, max_features='log2',\n",
       "                        n_estimators=75))"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_search.best_params_, random_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "b5c88bd3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-29T09:04:04.000313Z",
     "start_time": "2023-01-29T09:04:03.549195Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-9 {color: black;background-color: white;}#sk-container-id-9 pre{padding: 0;}#sk-container-id-9 div.sk-toggleable {background-color: white;}#sk-container-id-9 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-9 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-9 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-9 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-9 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-9 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-9 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-9 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-9 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-9 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-9 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-9 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-9 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-9 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-9 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-9 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-9 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-9 div.sk-item {position: relative;z-index: 1;}#sk-container-id-9 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-9 div.sk-item::before, #sk-container-id-9 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-9 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-9 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-9 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-9 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-9 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-9 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-9 div.sk-label-container {text-align: center;}#sk-container-id-9 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-9 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-9\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier(bootstrap=False, max_depth=8, max_features=&#x27;log2&#x27;,\n",
       "                       n_estimators=75)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-11\" type=\"checkbox\" checked><label for=\"sk-estimator-id-11\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(bootstrap=False, max_depth=8, max_features=&#x27;log2&#x27;,\n",
       "                       n_estimators=75)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestClassifier(bootstrap=False, max_depth=8, max_features='log2',\n",
       "                       n_estimators=75)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf= RandomForestClassifier(bootstrap=False, max_depth=8, max_features='log2',\n",
    "                       n_estimators=75)\n",
    "rf.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "c3850378",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-29T09:05:28.462481Z",
     "start_time": "2023-01-29T09:05:28.384458Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.9076690211907165, 0.7116935483870968)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf.score(X_train, Y_train), rf.score(X_test, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "8e849cf2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-29T09:06:18.422094Z",
     "start_time": "2023-01-29T09:06:18.342669Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[176  64]\n",
      " [ 89 167]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.66      0.73      0.70       240\n",
      "         1.0       0.72      0.65      0.69       256\n",
      "\n",
      "    accuracy                           0.69       496\n",
      "   macro avg       0.69      0.69      0.69       496\n",
      "weighted avg       0.69      0.69      0.69       496\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pred3 = rf.predict(X_train)\n",
    "pred_test3 = rf.predict(X_test)\n",
    "\n",
    "print(confusion_matrix(Y_test, pred_test2))\n",
    "\n",
    "print(classification_report(Y_test, pred_test2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "3670bfc8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-29T09:08:31.578182Z",
     "start_time": "2023-01-29T09:07:46.671676Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-10 {color: black;background-color: white;}#sk-container-id-10 pre{padding: 0;}#sk-container-id-10 div.sk-toggleable {background-color: white;}#sk-container-id-10 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-10 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-10 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-10 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-10 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-10 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-10 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-10 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-10 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-10 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-10 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-10 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-10 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-10 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-10 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-10 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-10 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-10 div.sk-item {position: relative;z-index: 1;}#sk-container-id-10 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-10 div.sk-item::before, #sk-container-id-10 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-10 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-10 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-10 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-10 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-10 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-10 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-10 div.sk-label-container {text-align: center;}#sk-container-id-10 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-10 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-10\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomizedSearchCV(cv=5,\n",
       "                   estimator=XGBClassifier(base_score=None, booster=None,\n",
       "                                           callbacks=None,\n",
       "                                           colsample_bylevel=None,\n",
       "                                           colsample_bynode=None,\n",
       "                                           colsample_bytree=None,\n",
       "                                           early_stopping_rounds=None,\n",
       "                                           enable_categorical=False,\n",
       "                                           eval_metric=None, gamma=None,\n",
       "                                           gpu_id=None, grow_policy=None,\n",
       "                                           importance_type=None,\n",
       "                                           interaction_constraints=None,\n",
       "                                           learning_rate=None, max_bin=None,...\n",
       "                                           reg_alpha=None, reg_lambda=None, ...),\n",
       "                   n_iter=5, n_jobs=-1,\n",
       "                   param_distributions={&#x27;colsample_bytree&#x27;: [0.3, 0.4, 0.5,\n",
       "                                                             0.7],\n",
       "                                        &#x27;gamma&#x27;: [0.0, 0.1, 0.2, 0.3, 0.4],\n",
       "                                        &#x27;learning_rate&#x27;: [0.05, 0.1, 0.15, 0.2,\n",
       "                                                          0.25, 0.3],\n",
       "                                        &#x27;max_depth&#x27;: [3, 4, 5, 6, 8, 10, 12, 15,\n",
       "                                                      17, 20],\n",
       "                                        &#x27;min_child_weight&#x27;: [0.25, 0.05, 0.5, 1,\n",
       "                                                             3, 5, 7],\n",
       "                                        &#x27;n_estimators&#x27;: [50, 100, 200, 150, 250,\n",
       "                                                         300]},\n",
       "                   random_state=42, scoring=&#x27;roc_auc&#x27;, verbose=3)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-12\" type=\"checkbox\" ><label for=\"sk-estimator-id-12\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomizedSearchCV</label><div class=\"sk-toggleable__content\"><pre>RandomizedSearchCV(cv=5,\n",
       "                   estimator=XGBClassifier(base_score=None, booster=None,\n",
       "                                           callbacks=None,\n",
       "                                           colsample_bylevel=None,\n",
       "                                           colsample_bynode=None,\n",
       "                                           colsample_bytree=None,\n",
       "                                           early_stopping_rounds=None,\n",
       "                                           enable_categorical=False,\n",
       "                                           eval_metric=None, gamma=None,\n",
       "                                           gpu_id=None, grow_policy=None,\n",
       "                                           importance_type=None,\n",
       "                                           interaction_constraints=None,\n",
       "                                           learning_rate=None, max_bin=None,...\n",
       "                                           reg_alpha=None, reg_lambda=None, ...),\n",
       "                   n_iter=5, n_jobs=-1,\n",
       "                   param_distributions={&#x27;colsample_bytree&#x27;: [0.3, 0.4, 0.5,\n",
       "                                                             0.7],\n",
       "                                        &#x27;gamma&#x27;: [0.0, 0.1, 0.2, 0.3, 0.4],\n",
       "                                        &#x27;learning_rate&#x27;: [0.05, 0.1, 0.15, 0.2,\n",
       "                                                          0.25, 0.3],\n",
       "                                        &#x27;max_depth&#x27;: [3, 4, 5, 6, 8, 10, 12, 15,\n",
       "                                                      17, 20],\n",
       "                                        &#x27;min_child_weight&#x27;: [0.25, 0.05, 0.5, 1,\n",
       "                                                             3, 5, 7],\n",
       "                                        &#x27;n_estimators&#x27;: [50, 100, 200, 150, 250,\n",
       "                                                         300]},\n",
       "                   random_state=42, scoring=&#x27;roc_auc&#x27;, verbose=3)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-13\" type=\"checkbox\" ><label for=\"sk-estimator-id-13\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: XGBClassifier</label><div class=\"sk-toggleable__content\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=None, gamma=None,\n",
       "              gpu_id=None, grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
       "              max_cat_to_onehot=None, max_delta_step=None, max_depth=None,\n",
       "              max_leaves=None, min_child_weight=None, missing=nan,\n",
       "              monotone_constraints=None, n_estimators=100, n_jobs=None,\n",
       "              num_parallel_tree=None, predictor=None, random_state=None,\n",
       "              reg_alpha=None, reg_lambda=None, ...)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-14\" type=\"checkbox\" ><label for=\"sk-estimator-id-14\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBClassifier</label><div class=\"sk-toggleable__content\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=None, gamma=None,\n",
       "              gpu_id=None, grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
       "              max_cat_to_onehot=None, max_delta_step=None, max_depth=None,\n",
       "              max_leaves=None, min_child_weight=None, missing=nan,\n",
       "              monotone_constraints=None, n_estimators=100, n_jobs=None,\n",
       "              num_parallel_tree=None, predictor=None, random_state=None,\n",
       "              reg_alpha=None, reg_lambda=None, ...)</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomizedSearchCV(cv=5,\n",
       "                   estimator=XGBClassifier(base_score=None, booster=None,\n",
       "                                           callbacks=None,\n",
       "                                           colsample_bylevel=None,\n",
       "                                           colsample_bynode=None,\n",
       "                                           colsample_bytree=None,\n",
       "                                           early_stopping_rounds=None,\n",
       "                                           enable_categorical=False,\n",
       "                                           eval_metric=None, gamma=None,\n",
       "                                           gpu_id=None, grow_policy=None,\n",
       "                                           importance_type=None,\n",
       "                                           interaction_constraints=None,\n",
       "                                           learning_rate=None, max_bin=None,...\n",
       "                                           reg_alpha=None, reg_lambda=None, ...),\n",
       "                   n_iter=5, n_jobs=-1,\n",
       "                   param_distributions={'colsample_bytree': [0.3, 0.4, 0.5,\n",
       "                                                             0.7],\n",
       "                                        'gamma': [0.0, 0.1, 0.2, 0.3, 0.4],\n",
       "                                        'learning_rate': [0.05, 0.1, 0.15, 0.2,\n",
       "                                                          0.25, 0.3],\n",
       "                                        'max_depth': [3, 4, 5, 6, 8, 10, 12, 15,\n",
       "                                                      17, 20],\n",
       "                                        'min_child_weight': [0.25, 0.05, 0.5, 1,\n",
       "                                                             3, 5, 7],\n",
       "                                        'n_estimators': [50, 100, 200, 150, 250,\n",
       "                                                         300]},\n",
       "                   random_state=42, scoring='roc_auc', verbose=3)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params={\n",
    " \"learning_rate\"    : [0.05, 0.10, 0.15, 0.20, 0.25, 0.30 ] ,\n",
    " \"max_depth\"        : [ 3, 4, 5, 6, 8, 10, 12, 15, 17, 20],\n",
    " \"min_child_weight\" : [0.25, 0.05, 0.5, 1, 3, 5, 7 ],\n",
    " \"gamma\"            : [ 0.0, 0.1, 0.2 , 0.3, 0.4 ],\n",
    " \"colsample_bytree\" : [ 0.3, 0.4, 0.5 , 0.7 ],\n",
    " \"n_estimators\"     : [50, 100, 200, 150, 250, 300]  \n",
    "}\n",
    "\n",
    "xgb_clf=XGBClassifier()\n",
    "\n",
    "random_search=RandomizedSearchCV(xgb_clf, param_distributions=params, n_iter=5, scoring='roc_auc',\n",
    "                                 n_jobs=-1, cv=5, verbose=3, random_state=42)\n",
    "random_search.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "b317628f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-29T09:09:12.275402Z",
     "start_time": "2023-01-29T09:09:12.260493Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'n_estimators': 250,\n",
       "  'min_child_weight': 1,\n",
       "  'max_depth': 17,\n",
       "  'learning_rate': 0.05,\n",
       "  'gamma': 0.0,\n",
       "  'colsample_bytree': 0.7},\n",
       " XGBClassifier(base_score=0.5, booster='gbtree', callbacks=None,\n",
       "               colsample_bylevel=1, colsample_bynode=1, colsample_bytree=0.7,\n",
       "               early_stopping_rounds=None, enable_categorical=False,\n",
       "               eval_metric=None, gamma=0.0, gpu_id=-1, grow_policy='depthwise',\n",
       "               importance_type=None, interaction_constraints='',\n",
       "               learning_rate=0.05, max_bin=256, max_cat_to_onehot=4,\n",
       "               max_delta_step=0, max_depth=17, max_leaves=0, min_child_weight=1,\n",
       "               missing=nan, monotone_constraints='()', n_estimators=250,\n",
       "               n_jobs=0, num_parallel_tree=1, predictor='auto', random_state=0,\n",
       "               reg_alpha=0, reg_lambda=1, ...))"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_search.best_params_, random_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "dc81957c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-29T09:13:11.282036Z",
     "start_time": "2023-01-29T09:13:08.932881Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[185  55]\n",
      " [ 77 179]]\n",
      "Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.71      0.77      0.74       240\n",
      "         1.0       0.76      0.70      0.73       256\n",
      "\n",
      "    accuracy                           0.73       496\n",
      "   macro avg       0.74      0.74      0.73       496\n",
      "weighted avg       0.74      0.73      0.73       496\n",
      "\n"
     ]
    }
   ],
   "source": [
    "xgb_clf_1 = XGBClassifier(n_estimators=250, max_depth=17, min_child_weight=1,learning_rate= 0.05)\n",
    "xgb_clf_1.fit(X_train, Y_train)\n",
    "predictions = xgb_clf_1.predict(X_test)\n",
    "\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(Y_test, predictions))\n",
    "\n",
    "print(\"Classification Report\")\n",
    "print(classification_report(Y_test, predictions))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "40a8de60",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-29T09:13:23.551004Z",
     "start_time": "2023-01-29T09:13:14.360396Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END colsample_bytree=0.4, gamma=0.1, learning_rate=0.1, max_depth=12, min_child_weight=0.25, n_estimators=150;, score=0.744 total time=   2.3s\n",
      "[CV 2/5] END colsample_bytree=0.3, gamma=0.0, learning_rate=0.15, max_depth=3, min_child_weight=1, n_estimators=200;, score=0.751 total time=   0.7s\n",
      "[CV 5/5] END colsample_bytree=0.3, gamma=0.0, learning_rate=0.15, max_depth=3, min_child_weight=1, n_estimators=200;, score=0.705 total time=   0.6s\n",
      "[CV 3/5] END colsample_bytree=0.7, gamma=0.0, learning_rate=0.05, max_depth=17, min_child_weight=1, n_estimators=250;, score=0.776 total time=   6.6s\n",
      "[CV 2/5] END colsample_bytree=0.7, gamma=0.2, learning_rate=0.25, max_depth=10, min_child_weight=0.25, n_estimators=200;, score=0.795 total time=   4.2s\n",
      "[CV 5/5] END colsample_bytree=0.7, gamma=0.2, learning_rate=0.25, max_depth=10, min_child_weight=0.25, n_estimators=200;, score=0.782 total time=   4.4s\n",
      "[CV 1/5] END colsample_bytree=0.4, gamma=0.1, learning_rate=0.1, max_depth=12, min_child_weight=0.25, n_estimators=150;, score=0.734 total time=   2.2s\n",
      "[CV 5/5] END colsample_bytree=0.4, gamma=0.1, learning_rate=0.1, max_depth=12, min_child_weight=0.25, n_estimators=150;, score=0.752 total time=   2.1s\n",
      "[CV 4/5] END colsample_bytree=0.7, gamma=0.0, learning_rate=0.05, max_depth=17, min_child_weight=1, n_estimators=250;, score=0.818 total time=   6.7s\n",
      "[CV 3/5] END colsample_bytree=0.7, gamma=0.2, learning_rate=0.25, max_depth=10, min_child_weight=0.25, n_estimators=200;, score=0.764 total time=   4.0s\n",
      "[CV 1/5] END colsample_bytree=0.3, gamma=0.4, learning_rate=0.15, max_depth=17, min_child_weight=3, n_estimators=250;, score=0.694 total time=   2.6s\n",
      "[CV 3/5] END colsample_bytree=0.3, gamma=0.4, learning_rate=0.15, max_depth=17, min_child_weight=3, n_estimators=250;, score=0.701 total time=   2.6s\n",
      "[CV 4/5] END colsample_bytree=0.4, gamma=0.1, learning_rate=0.1, max_depth=12, min_child_weight=0.25, n_estimators=150;, score=0.770 total time=   2.3s\n",
      "[CV 3/5] END colsample_bytree=0.3, gamma=0.0, learning_rate=0.15, max_depth=3, min_child_weight=1, n_estimators=200;, score=0.726 total time=   0.7s\n",
      "[CV 1/5] END colsample_bytree=0.7, gamma=0.0, learning_rate=0.05, max_depth=17, min_child_weight=1, n_estimators=250;, score=0.770 total time=   6.4s\n",
      "[CV 5/5] END colsample_bytree=0.7, gamma=0.0, learning_rate=0.05, max_depth=17, min_child_weight=1, n_estimators=250;, score=0.782 total time=   6.4s\n",
      "[CV 2/5] END colsample_bytree=0.3, gamma=0.4, learning_rate=0.15, max_depth=17, min_child_weight=3, n_estimators=250;, score=0.731 total time=   2.6s\n",
      "[CV 4/5] END colsample_bytree=0.3, gamma=0.4, learning_rate=0.15, max_depth=17, min_child_weight=3, n_estimators=250;, score=0.743 total time=   2.5s\n",
      "[CV 2/5] END colsample_bytree=0.4, gamma=0.1, learning_rate=0.1, max_depth=12, min_child_weight=0.25, n_estimators=150;, score=0.754 total time=   2.2s\n",
      "[CV 1/5] END colsample_bytree=0.3, gamma=0.0, learning_rate=0.15, max_depth=3, min_child_weight=1, n_estimators=200;, score=0.730 total time=   0.7s\n",
      "[CV 4/5] END colsample_bytree=0.3, gamma=0.0, learning_rate=0.15, max_depth=3, min_child_weight=1, n_estimators=200;, score=0.753 total time=   0.6s\n",
      "[CV 2/5] END colsample_bytree=0.7, gamma=0.0, learning_rate=0.05, max_depth=17, min_child_weight=1, n_estimators=250;, score=0.789 total time=   6.6s\n",
      "[CV 1/5] END colsample_bytree=0.7, gamma=0.2, learning_rate=0.25, max_depth=10, min_child_weight=0.25, n_estimators=200;, score=0.740 total time=   4.2s\n",
      "[CV 4/5] END colsample_bytree=0.7, gamma=0.2, learning_rate=0.25, max_depth=10, min_child_weight=0.25, n_estimators=200;, score=0.816 total time=   4.4s\n",
      "[CV 5/5] END colsample_bytree=0.3, gamma=0.4, learning_rate=0.15, max_depth=17, min_child_weight=3, n_estimators=250;, score=0.716 total time=   2.4s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([0.68010076, 0.697733  , 0.73484848, 0.73484848, 0.73232323]),\n",
       " 0.022800936535572747,\n",
       " 0.7159707910337633)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k_fold = KFold(n_splits=5, shuffle=True, random_state=123)\n",
    "cvscore_train = cross_val_score(estimator=xgb_clf_1, X=X_train, y=Y_train, cv=k_fold)\n",
    "\n",
    "cvscore_train, cvscore_train.std(), cvscore_train.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "9706d7a2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-29T09:17:12.349789Z",
     "start_time": "2023-01-29T09:17:10.833292Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0.69      , 0.66666667, 0.67676768, 0.67676768, 0.61616162]),\n",
       " 0.0256497565131277,\n",
       " 0.6652727272727272)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k_fold = KFold(n_splits=5, shuffle=True, random_state=123)\n",
    "cvscore_dt_test = cross_val_score(estimator=xgb_clf_1, X=X_test, y=Y_test, cv=k_fold)\n",
    "\n",
    "cvscore_dt_test, cvscore_dt_test.std(), cvscore_dt_test.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "0860f052",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-29T09:22:00.510784Z",
     "start_time": "2023-01-29T09:22:00.299913Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1440x1800 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "\n",
    "xgb.plot_importance(xgb_clf_1)\n",
    "plt.figure(figsize = (20, 25))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "641d609e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-29T09:23:41.068582Z",
     "start_time": "2023-01-29T09:23:41.044342Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ph</th>\n",
       "      <th>Hardness</th>\n",
       "      <th>Solids</th>\n",
       "      <th>Chloramines</th>\n",
       "      <th>Sulfate</th>\n",
       "      <th>Conductivity</th>\n",
       "      <th>Organic_carbon</th>\n",
       "      <th>Trihalomethanes</th>\n",
       "      <th>Turbidity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ph</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.054873</td>\n",
       "      <td>-0.059621</td>\n",
       "      <td>0.002845</td>\n",
       "      <td>0.009547</td>\n",
       "      <td>0.016723</td>\n",
       "      <td>0.026679</td>\n",
       "      <td>0.015809</td>\n",
       "      <td>-0.031114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Hardness</th>\n",
       "      <td>0.054873</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.052946</td>\n",
       "      <td>-0.026845</td>\n",
       "      <td>-0.091405</td>\n",
       "      <td>-0.019862</td>\n",
       "      <td>0.008405</td>\n",
       "      <td>-0.004756</td>\n",
       "      <td>-0.012773</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Solids</th>\n",
       "      <td>-0.059621</td>\n",
       "      <td>-0.052946</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.061321</td>\n",
       "      <td>-0.177602</td>\n",
       "      <td>0.011682</td>\n",
       "      <td>-0.006309</td>\n",
       "      <td>-0.009538</td>\n",
       "      <td>0.020198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Chloramines</th>\n",
       "      <td>0.002845</td>\n",
       "      <td>-0.026845</td>\n",
       "      <td>-0.061321</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.034691</td>\n",
       "      <td>-0.018437</td>\n",
       "      <td>-0.020192</td>\n",
       "      <td>0.010925</td>\n",
       "      <td>0.000192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sulfate</th>\n",
       "      <td>0.009547</td>\n",
       "      <td>-0.091405</td>\n",
       "      <td>-0.177602</td>\n",
       "      <td>0.034691</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.024858</td>\n",
       "      <td>0.024010</td>\n",
       "      <td>-0.024508</td>\n",
       "      <td>-0.011019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Conductivity</th>\n",
       "      <td>0.016723</td>\n",
       "      <td>-0.019862</td>\n",
       "      <td>0.011682</td>\n",
       "      <td>-0.018437</td>\n",
       "      <td>-0.024858</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.019271</td>\n",
       "      <td>0.008446</td>\n",
       "      <td>-0.006655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Organic_carbon</th>\n",
       "      <td>0.026679</td>\n",
       "      <td>0.008405</td>\n",
       "      <td>-0.006309</td>\n",
       "      <td>-0.020192</td>\n",
       "      <td>0.024010</td>\n",
       "      <td>0.019271</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.009377</td>\n",
       "      <td>-0.015829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Trihalomethanes</th>\n",
       "      <td>0.015809</td>\n",
       "      <td>-0.004756</td>\n",
       "      <td>-0.009538</td>\n",
       "      <td>0.010925</td>\n",
       "      <td>-0.024508</td>\n",
       "      <td>0.008446</td>\n",
       "      <td>-0.009377</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.029348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Turbidity</th>\n",
       "      <td>-0.031114</td>\n",
       "      <td>-0.012773</td>\n",
       "      <td>0.020198</td>\n",
       "      <td>0.000192</td>\n",
       "      <td>-0.011019</td>\n",
       "      <td>-0.006655</td>\n",
       "      <td>-0.015829</td>\n",
       "      <td>-0.029348</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       ph  Hardness    Solids  Chloramines   Sulfate  \\\n",
       "ph               1.000000  0.054873 -0.059621     0.002845  0.009547   \n",
       "Hardness         0.054873  1.000000 -0.052946    -0.026845 -0.091405   \n",
       "Solids          -0.059621 -0.052946  1.000000    -0.061321 -0.177602   \n",
       "Chloramines      0.002845 -0.026845 -0.061321     1.000000  0.034691   \n",
       "Sulfate          0.009547 -0.091405 -0.177602     0.034691  1.000000   \n",
       "Conductivity     0.016723 -0.019862  0.011682    -0.018437 -0.024858   \n",
       "Organic_carbon   0.026679  0.008405 -0.006309    -0.020192  0.024010   \n",
       "Trihalomethanes  0.015809 -0.004756 -0.009538     0.010925 -0.024508   \n",
       "Turbidity       -0.031114 -0.012773  0.020198     0.000192 -0.011019   \n",
       "\n",
       "                 Conductivity  Organic_carbon  Trihalomethanes  Turbidity  \n",
       "ph                   0.016723        0.026679         0.015809  -0.031114  \n",
       "Hardness            -0.019862        0.008405        -0.004756  -0.012773  \n",
       "Solids               0.011682       -0.006309        -0.009538   0.020198  \n",
       "Chloramines         -0.018437       -0.020192         0.010925   0.000192  \n",
       "Sulfate             -0.024858        0.024010        -0.024508  -0.011019  \n",
       "Conductivity         1.000000        0.019271         0.008446  -0.006655  \n",
       "Organic_carbon       0.019271        1.000000        -0.009377  -0.015829  \n",
       "Trihalomethanes      0.008446       -0.009377         1.000000  -0.029348  \n",
       "Turbidity           -0.006655       -0.015829        -0.029348   1.000000  "
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "153badbf",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-29T12:44:28.042163Z",
     "start_time": "2023-01-29T12:44:27.798624Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-15 {color: black;background-color: white;}#sk-container-id-15 pre{padding: 0;}#sk-container-id-15 div.sk-toggleable {background-color: white;}#sk-container-id-15 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-15 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-15 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-15 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-15 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-15 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-15 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-15 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-15 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-15 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-15 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-15 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-15 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-15 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-15 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-15 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-15 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-15 div.sk-item {position: relative;z-index: 1;}#sk-container-id-15 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-15 div.sk-item::before, #sk-container-id-15 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-15 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-15 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-15 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-15 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-15 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-15 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-15 div.sk-label-container {text-align: center;}#sk-container-id-15 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-15 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-15\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>SVC(random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-19\" type=\"checkbox\" checked><label for=\"sk-estimator-id-19\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SVC</label><div class=\"sk-toggleable__content\"><pre>SVC(random_state=42)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "SVC(random_state=42)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm = SVC(random_state = 42)\n",
    "svm.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "f192d0a5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-29T12:45:14.689108Z",
     "start_time": "2023-01-29T12:45:14.538913Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[154  86]\n",
      " [ 81 175]]\n",
      "Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.66      0.64      0.65       240\n",
      "         1.0       0.67      0.68      0.68       256\n",
      "\n",
      "    accuracy                           0.66       496\n",
      "   macro avg       0.66      0.66      0.66       496\n",
      "weighted avg       0.66      0.66      0.66       496\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "predictions = svm.predict(X_test)\n",
    "\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(Y_test, predictions))\n",
    "\n",
    "print(\"Classification Report\")\n",
    "print(classification_report(Y_test, predictions))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "239d44af",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-29T12:16:35.026464Z",
     "start_time": "2023-01-29T12:14:22.918344Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 4, 'degree': 3, 'kernel': 'rbf'} 0.6558901356130574\n"
     ]
    }
   ],
   "source": [
    "param_grid={\n",
    "    'C':[0.1,0.5,1,2,3,4,5],\n",
    "    'kernel':['linear', 'poly', 'rbf', 'sigmoid'],\n",
    "    'degree':[3,4,5,6,7]\n",
    "    \n",
    "}\n",
    "grid_SVC=GridSearchCV(SVC(), param_grid, cv=5, scoring='accuracy')\n",
    "grid_SVC.fit(X_train,Y_train)\n",
    "print(grid_SVC.best_params_,grid_SVC.best_score_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "d306d3f8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-29T12:46:27.029051Z",
     "start_time": "2023-01-29T12:46:26.738350Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-16 {color: black;background-color: white;}#sk-container-id-16 pre{padding: 0;}#sk-container-id-16 div.sk-toggleable {background-color: white;}#sk-container-id-16 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-16 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-16 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-16 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-16 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-16 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-16 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-16 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-16 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-16 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-16 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-16 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-16 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-16 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-16 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-16 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-16 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-16 div.sk-item {position: relative;z-index: 1;}#sk-container-id-16 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-16 div.sk-item::before, #sk-container-id-16 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-16 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-16 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-16 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-16 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-16 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-16 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-16 div.sk-label-container {text-align: center;}#sk-container-id-16 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-16 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-16\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>SVC(C=4, random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-20\" type=\"checkbox\" checked><label for=\"sk-estimator-id-20\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SVC</label><div class=\"sk-toggleable__content\"><pre>SVC(C=4, random_state=42)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "SVC(C=4, random_state=42)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm_1 = SVC(random_state = 42, C=4, kernel='rbf')\n",
    "svm_1.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "da739a11",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-29T12:46:28.101531Z",
     "start_time": "2023-01-29T12:46:27.946084Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[148  92]\n",
      " [ 92 164]]\n",
      "Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.62      0.62      0.62       240\n",
      "         1.0       0.64      0.64      0.64       256\n",
      "\n",
      "    accuracy                           0.63       496\n",
      "   macro avg       0.63      0.63      0.63       496\n",
      "weighted avg       0.63      0.63      0.63       496\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions = svm_1.predict(X_test)\n",
    "\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(Y_test, predictions))\n",
    "\n",
    "print(\"Classification Report\")\n",
    "print(classification_report(Y_test, predictions))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "8250b24d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-29T13:45:16.542415Z",
     "start_time": "2023-01-29T13:43:08.527610Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow\n",
      "  Downloading tensorflow-2.11.0-cp39-cp39-macosx_10_14_x86_64.whl (244.3 MB)\n",
      "\u001b[K     |████████████████████████████████| 244.3 MB 4.4 kB/s eta 0:00:01     |█▊                              | 13.3 MB 11.6 MB/s eta 0:00:20     |█████████████████████▉          | 166.9 MB 2.4 MB/s eta 0:00:33\n",
      "\u001b[?25hCollecting tensorflow-estimator<2.12,>=2.11.0\n",
      "  Downloading tensorflow_estimator-2.11.0-py2.py3-none-any.whl (439 kB)\n",
      "\u001b[K     |████████████████████████████████| 439 kB 3.8 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting absl-py>=1.0.0\n",
      "  Downloading absl_py-1.4.0-py3-none-any.whl (126 kB)\n",
      "\u001b[K     |████████████████████████████████| 126 kB 3.8 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting opt-einsum>=2.3.2\n",
      "  Downloading opt_einsum-3.3.0-py3-none-any.whl (65 kB)\n",
      "\u001b[K     |████████████████████████████████| 65 kB 2.5 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: wrapt>=1.11.0 in /Users/shubhamswarnakar/opt/anaconda3/lib/python3.9/site-packages (from tensorflow) (1.12.1)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /Users/shubhamswarnakar/.local/lib/python3.9/site-packages (from tensorflow) (3.10.0.0)\n",
      "Requirement already satisfied: six>=1.12.0 in /Users/shubhamswarnakar/opt/anaconda3/lib/python3.9/site-packages (from tensorflow) (1.16.0)\n",
      "Collecting libclang>=13.0.0\n",
      "  Downloading libclang-15.0.6.1-py2.py3-none-macosx_10_9_x86_64.whl (25.0 MB)\n",
      "\u001b[K     |████████████████████████████████| 25.0 MB 3.8 MB/s eta 0:00:01     |█████████████████████▍          | 16.7 MB 2.9 MB/s eta 0:00:03\n",
      "\u001b[?25hCollecting flatbuffers>=2.0\n",
      "  Downloading flatbuffers-23.1.21-py2.py3-none-any.whl (26 kB)\n",
      "Collecting gast<=0.4.0,>=0.2.1\n",
      "  Downloading gast-0.4.0-py3-none-any.whl (9.8 kB)\n",
      "Requirement already satisfied: setuptools in /Users/shubhamswarnakar/opt/anaconda3/lib/python3.9/site-packages (from tensorflow) (58.0.4)\n",
      "Requirement already satisfied: numpy>=1.20 in /Users/shubhamswarnakar/opt/anaconda3/lib/python3.9/site-packages (from tensorflow) (1.20.3)\n",
      "Collecting keras<2.12,>=2.11.0\n",
      "  Downloading keras-2.11.0-py2.py3-none-any.whl (1.7 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.7 MB 4.4 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting tensorboard<2.12,>=2.11\n",
      "  Downloading tensorboard-2.11.2-py3-none-any.whl (6.0 MB)\n",
      "\u001b[K     |████████████████████████████████| 6.0 MB 3.2 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting grpcio<2.0,>=1.24.3\n",
      "  Downloading grpcio-1.51.1-cp39-cp39-macosx_10_10_x86_64.whl (4.6 MB)\n",
      "\u001b[K     |████████████████████████████████| 4.6 MB 3.9 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting tensorflow-io-gcs-filesystem>=0.23.1\n",
      "  Downloading tensorflow_io_gcs_filesystem-0.30.0-cp39-cp39-macosx_10_14_x86_64.whl (1.6 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.6 MB 4.3 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting astunparse>=1.6.0\n",
      "  Downloading astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n",
      "Collecting google-pasta>=0.1.1\n",
      "  Downloading google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
      "\u001b[K     |████████████████████████████████| 57 kB 3.8 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: packaging in /Users/shubhamswarnakar/opt/anaconda3/lib/python3.9/site-packages (from tensorflow) (21.0)\n",
      "Collecting termcolor>=1.1.0\n",
      "  Downloading termcolor-2.2.0-py3-none-any.whl (6.6 kB)\n",
      "Requirement already satisfied: h5py>=2.9.0 in /Users/shubhamswarnakar/opt/anaconda3/lib/python3.9/site-packages (from tensorflow) (3.2.1)\n",
      "Collecting protobuf<3.20,>=3.9.2\n",
      "  Downloading protobuf-3.19.6-cp39-cp39-macosx_10_9_x86_64.whl (980 kB)\n",
      "\u001b[K     |████████████████████████████████| 980 kB 5.0 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: wheel<1.0,>=0.23.0 in /Users/shubhamswarnakar/opt/anaconda3/lib/python3.9/site-packages (from astunparse>=1.6.0->tensorflow) (0.37.0)\n",
      "Collecting google-auth<3,>=1.6.3\n",
      "  Downloading google_auth-2.16.0-py2.py3-none-any.whl (177 kB)\n",
      "\u001b[K     |████████████████████████████████| 177 kB 5.9 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting tensorboard-plugin-wit>=1.6.0\n",
      "  Downloading tensorboard_plugin_wit-1.8.1-py3-none-any.whl (781 kB)\n",
      "\u001b[K     |████████████████████████████████| 781 kB 5.5 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: werkzeug>=1.0.1 in /Users/shubhamswarnakar/opt/anaconda3/lib/python3.9/site-packages (from tensorboard<2.12,>=2.11->tensorflow) (2.0.2)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /Users/shubhamswarnakar/.local/lib/python3.9/site-packages (from tensorboard<2.12,>=2.11->tensorflow) (2.25.1)\n",
      "Collecting tensorboard-data-server<0.7.0,>=0.6.0\n",
      "  Downloading tensorboard_data_server-0.6.1-py3-none-macosx_10_9_x86_64.whl (3.5 MB)\n",
      "\u001b[K     |████████████████████████████████| 3.5 MB 2.6 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting markdown>=2.6.8\n",
      "  Downloading Markdown-3.4.1-py3-none-any.whl (93 kB)\n",
      "\u001b[K     |████████████████████████████████| 93 kB 1.6 MB/s eta 0:00:011\n",
      "\u001b[?25hCollecting google-auth-oauthlib<0.5,>=0.4.1\n",
      "  Downloading google_auth_oauthlib-0.4.6-py2.py3-none-any.whl (18 kB)\n",
      "Collecting cachetools<6.0,>=2.0.0\n",
      "  Downloading cachetools-5.3.0-py3-none-any.whl (9.3 kB)\n",
      "Collecting pyasn1-modules>=0.2.1\n",
      "  Downloading pyasn1_modules-0.2.8-py2.py3-none-any.whl (155 kB)\n",
      "\u001b[K     |████████████████████████████████| 155 kB 4.8 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting rsa<5,>=3.1.4\n",
      "  Downloading rsa-4.9-py3-none-any.whl (34 kB)\n",
      "Collecting requests-oauthlib>=0.7.0\n",
      "  Downloading requests_oauthlib-1.3.1-py2.py3-none-any.whl (23 kB)\n",
      "Requirement already satisfied: importlib-metadata>=4.4 in /Users/shubhamswarnakar/opt/anaconda3/lib/python3.9/site-packages (from markdown>=2.6.8->tensorboard<2.12,>=2.11->tensorflow) (4.8.1)\n",
      "Requirement already satisfied: zipp>=0.5 in /Users/shubhamswarnakar/opt/anaconda3/lib/python3.9/site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.12,>=2.11->tensorflow) (3.6.0)\n",
      "Collecting pyasn1<0.5.0,>=0.4.6\n",
      "  Downloading pyasn1-0.4.8-py2.py3-none-any.whl (77 kB)\n",
      "\u001b[K     |████████████████████████████████| 77 kB 3.5 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: idna<3,>=2.5 in /Users/shubhamswarnakar/.local/lib/python3.9/site-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow) (2.10)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /Users/shubhamswarnakar/opt/anaconda3/lib/python3.9/site-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow) (1.26.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/shubhamswarnakar/opt/anaconda3/lib/python3.9/site-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow) (2021.10.8)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in /Users/shubhamswarnakar/opt/anaconda3/lib/python3.9/site-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow) (4.0.0)\n",
      "Collecting oauthlib>=3.0.0\n",
      "  Downloading oauthlib-3.2.2-py3-none-any.whl (151 kB)\n",
      "\u001b[K     |████████████████████████████████| 151 kB 6.5 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: pyparsing>=2.0.2 in /Users/shubhamswarnakar/opt/anaconda3/lib/python3.9/site-packages (from packaging->tensorflow) (3.0.4)\n",
      "Installing collected packages: pyasn1, rsa, pyasn1-modules, oauthlib, cachetools, requests-oauthlib, google-auth, tensorboard-plugin-wit, tensorboard-data-server, protobuf, markdown, grpcio, google-auth-oauthlib, absl-py, termcolor, tensorflow-io-gcs-filesystem, tensorflow-estimator, tensorboard, opt-einsum, libclang, keras, google-pasta, gast, flatbuffers, astunparse, tensorflow\n",
      "Successfully installed absl-py-1.4.0 astunparse-1.6.3 cachetools-5.3.0 flatbuffers-23.1.21 gast-0.4.0 google-auth-2.16.0 google-auth-oauthlib-0.4.6 google-pasta-0.2.0 grpcio-1.51.1 keras-2.11.0 libclang-15.0.6.1 markdown-3.4.1 oauthlib-3.2.2 opt-einsum-3.3.0 protobuf-3.19.6 pyasn1-0.4.8 pyasn1-modules-0.2.8 requests-oauthlib-1.3.1 rsa-4.9 tensorboard-2.11.2 tensorboard-data-server-0.6.1 tensorboard-plugin-wit-1.8.1 tensorflow-2.11.0 tensorflow-estimator-2.11.0 tensorflow-io-gcs-filesystem-0.30.0 termcolor-2.2.0\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "609b4f93",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-29T13:46:07.514606Z",
     "start_time": "2023-01-29T13:45:24.382303Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-29 19:15:24.836861: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from tensorflow import keras\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.layers import LeakyReLU\n",
    "from tensorflow.keras import models\n",
    "from tensorflow.keras.layers import BatchNormalization, Dropout\n",
    "from tensorflow.keras.optimizers import Adam, Adagrad, RMSprop, SGD\n",
    "from tensorflow.keras.layers import Activation\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "54e3d7e1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-29T13:58:34.449584Z",
     "start_time": "2023-01-29T13:58:34.440661Z"
    }
   },
   "outputs": [],
   "source": [
    "X_val, X_test, Y_val, Y_test = train_test_split(X_test,Y_test, test_size = 0.5, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "71ee3879",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-29T13:47:11.105175Z",
     "start_time": "2023-01-29T13:47:10.833940Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-29 19:17:10.849642: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "model = models.Sequential()\n",
    "\n",
    "model.add(layers.Dense(16, input_shape=(9,)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation(\"relu\"))\n",
    "\n",
    "model.add(layers.Dense(32))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation(\"relu\"))\n",
    "\n",
    "model.add(layers.Dense(16))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation(\"relu\"))\n",
    "\n",
    "model.add(layers.Dense(1))\n",
    "model.add(Activation(\"sigmoid\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "c4cba121",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-29T13:47:28.556603Z",
     "start_time": "2023-01-29T13:47:28.534338Z"
    }
   },
   "outputs": [],
   "source": [
    "opt = Adam(learning_rate=0.001)\n",
    "\n",
    "model.compile(loss=\"binary_crossentropy\",\n",
    "              optimizer=opt,\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "fbe19d26",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-29T13:47:37.499414Z",
     "start_time": "2023-01-29T13:47:37.438932Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 16)                160       \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 16)               64        \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " activation (Activation)     (None, 16)                0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 32)                544       \n",
      "                                                                 \n",
      " batch_normalization_1 (Batc  (None, 32)               128       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " activation_1 (Activation)   (None, 32)                0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 16)                528       \n",
      "                                                                 \n",
      " batch_normalization_2 (Batc  (None, 16)               64        \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " activation_2 (Activation)   (None, 16)                0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 1)                 17        \n",
      "                                                                 \n",
      " activation_3 (Activation)   (None, 1)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,505\n",
      "Trainable params: 1,377\n",
      "Non-trainable params: 128\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "c3637ee4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-29T13:49:22.531086Z",
     "start_time": "2023-01-29T13:47:52.535549Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "62/62 [==============================] - 4s 10ms/step - loss: 0.7439 - accuracy: 0.5252 - val_loss: 0.6690 - val_accuracy: 0.5968\n",
      "Epoch 2/300\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.6822 - accuracy: 0.5621 - val_loss: 0.6607 - val_accuracy: 0.6008\n",
      "Epoch 3/300\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.6636 - accuracy: 0.5832 - val_loss: 0.6545 - val_accuracy: 0.6169\n",
      "Epoch 4/300\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.6557 - accuracy: 0.6044 - val_loss: 0.6445 - val_accuracy: 0.6210\n",
      "Epoch 5/300\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.6464 - accuracy: 0.6181 - val_loss: 0.6351 - val_accuracy: 0.6331\n",
      "Epoch 6/300\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.6409 - accuracy: 0.6196 - val_loss: 0.6268 - val_accuracy: 0.6250\n",
      "Epoch 7/300\n",
      "62/62 [==============================] - 0s 5ms/step - loss: 0.6321 - accuracy: 0.6468 - val_loss: 0.6206 - val_accuracy: 0.6613\n",
      "Epoch 8/300\n",
      "62/62 [==============================] - 0s 5ms/step - loss: 0.6208 - accuracy: 0.6504 - val_loss: 0.6194 - val_accuracy: 0.6452\n",
      "Epoch 9/300\n",
      "62/62 [==============================] - 0s 5ms/step - loss: 0.6149 - accuracy: 0.6529 - val_loss: 0.6141 - val_accuracy: 0.6452\n",
      "Epoch 10/300\n",
      "62/62 [==============================] - 0s 5ms/step - loss: 0.6188 - accuracy: 0.6403 - val_loss: 0.6110 - val_accuracy: 0.6331\n",
      "Epoch 11/300\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.6114 - accuracy: 0.6519 - val_loss: 0.6150 - val_accuracy: 0.6290\n",
      "Epoch 12/300\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.6094 - accuracy: 0.6579 - val_loss: 0.6120 - val_accuracy: 0.6331\n",
      "Epoch 13/300\n",
      "62/62 [==============================] - 0s 6ms/step - loss: 0.5984 - accuracy: 0.6761 - val_loss: 0.6161 - val_accuracy: 0.6250\n",
      "Epoch 14/300\n",
      "62/62 [==============================] - 0s 5ms/step - loss: 0.6022 - accuracy: 0.6801 - val_loss: 0.6075 - val_accuracy: 0.6371\n",
      "Epoch 15/300\n",
      "62/62 [==============================] - 0s 5ms/step - loss: 0.5980 - accuracy: 0.6801 - val_loss: 0.6139 - val_accuracy: 0.6411\n",
      "Epoch 16/300\n",
      "62/62 [==============================] - 0s 5ms/step - loss: 0.5985 - accuracy: 0.6821 - val_loss: 0.6059 - val_accuracy: 0.6411\n",
      "Epoch 17/300\n",
      "62/62 [==============================] - 0s 5ms/step - loss: 0.5860 - accuracy: 0.6847 - val_loss: 0.6079 - val_accuracy: 0.6371\n",
      "Epoch 18/300\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.5824 - accuracy: 0.6922 - val_loss: 0.6129 - val_accuracy: 0.6411\n",
      "Epoch 19/300\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.5896 - accuracy: 0.6796 - val_loss: 0.6106 - val_accuracy: 0.6290\n",
      "Epoch 20/300\n",
      "62/62 [==============================] - 0s 5ms/step - loss: 0.5791 - accuracy: 0.6907 - val_loss: 0.6189 - val_accuracy: 0.6371\n",
      "Epoch 21/300\n",
      "62/62 [==============================] - 0s 6ms/step - loss: 0.5785 - accuracy: 0.6892 - val_loss: 0.6180 - val_accuracy: 0.6210\n",
      "Epoch 22/300\n",
      "62/62 [==============================] - 0s 5ms/step - loss: 0.5829 - accuracy: 0.6922 - val_loss: 0.6154 - val_accuracy: 0.6452\n",
      "Epoch 23/300\n",
      "62/62 [==============================] - 0s 7ms/step - loss: 0.5788 - accuracy: 0.6907 - val_loss: 0.6176 - val_accuracy: 0.6290\n",
      "Epoch 24/300\n",
      "62/62 [==============================] - 0s 6ms/step - loss: 0.5756 - accuracy: 0.7023 - val_loss: 0.6148 - val_accuracy: 0.6331\n",
      "Epoch 25/300\n",
      "62/62 [==============================] - 0s 6ms/step - loss: 0.5768 - accuracy: 0.7003 - val_loss: 0.6206 - val_accuracy: 0.6331\n",
      "Epoch 26/300\n",
      "62/62 [==============================] - 0s 6ms/step - loss: 0.5704 - accuracy: 0.7028 - val_loss: 0.6168 - val_accuracy: 0.6411\n",
      "Epoch 27/300\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.5706 - accuracy: 0.6963 - val_loss: 0.6209 - val_accuracy: 0.6290\n",
      "Epoch 28/300\n",
      "62/62 [==============================] - 0s 5ms/step - loss: 0.5690 - accuracy: 0.6973 - val_loss: 0.6244 - val_accuracy: 0.6290\n",
      "Epoch 29/300\n",
      "62/62 [==============================] - 0s 7ms/step - loss: 0.5783 - accuracy: 0.7043 - val_loss: 0.6259 - val_accuracy: 0.6371\n",
      "Epoch 30/300\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.5619 - accuracy: 0.7064 - val_loss: 0.6170 - val_accuracy: 0.6452\n",
      "Epoch 31/300\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.5640 - accuracy: 0.7033 - val_loss: 0.6247 - val_accuracy: 0.6411\n",
      "Epoch 32/300\n",
      "62/62 [==============================] - 0s 6ms/step - loss: 0.5618 - accuracy: 0.6993 - val_loss: 0.6188 - val_accuracy: 0.6331\n",
      "Epoch 33/300\n",
      "62/62 [==============================] - 0s 7ms/step - loss: 0.5572 - accuracy: 0.7008 - val_loss: 0.6152 - val_accuracy: 0.6452\n",
      "Epoch 34/300\n",
      "62/62 [==============================] - 0s 6ms/step - loss: 0.5537 - accuracy: 0.7139 - val_loss: 0.6055 - val_accuracy: 0.6532\n",
      "Epoch 35/300\n",
      "62/62 [==============================] - 0s 7ms/step - loss: 0.5661 - accuracy: 0.6958 - val_loss: 0.6078 - val_accuracy: 0.6290\n",
      "Epoch 36/300\n",
      "62/62 [==============================] - 0s 6ms/step - loss: 0.5601 - accuracy: 0.7008 - val_loss: 0.6054 - val_accuracy: 0.6371\n",
      "Epoch 37/300\n",
      "62/62 [==============================] - 0s 5ms/step - loss: 0.5583 - accuracy: 0.7003 - val_loss: 0.6069 - val_accuracy: 0.6371\n",
      "Epoch 38/300\n",
      "62/62 [==============================] - 0s 6ms/step - loss: 0.5697 - accuracy: 0.7018 - val_loss: 0.6136 - val_accuracy: 0.6331\n",
      "Epoch 39/300\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.5534 - accuracy: 0.7114 - val_loss: 0.6178 - val_accuracy: 0.6331\n",
      "Epoch 40/300\n",
      "62/62 [==============================] - 0s 5ms/step - loss: 0.5568 - accuracy: 0.7139 - val_loss: 0.6165 - val_accuracy: 0.6250\n",
      "Epoch 41/300\n",
      "62/62 [==============================] - 0s 6ms/step - loss: 0.5468 - accuracy: 0.7104 - val_loss: 0.6138 - val_accuracy: 0.6331\n",
      "Epoch 42/300\n",
      "62/62 [==============================] - 0s 6ms/step - loss: 0.5493 - accuracy: 0.7220 - val_loss: 0.6217 - val_accuracy: 0.6371\n",
      "Epoch 43/300\n",
      "62/62 [==============================] - 0s 6ms/step - loss: 0.5471 - accuracy: 0.7139 - val_loss: 0.6153 - val_accuracy: 0.6290\n",
      "Epoch 44/300\n",
      "62/62 [==============================] - 0s 5ms/step - loss: 0.5565 - accuracy: 0.7159 - val_loss: 0.6093 - val_accuracy: 0.6532\n",
      "Epoch 45/300\n",
      "62/62 [==============================] - 0s 6ms/step - loss: 0.5442 - accuracy: 0.7195 - val_loss: 0.6209 - val_accuracy: 0.6169\n",
      "Epoch 46/300\n",
      "62/62 [==============================] - 0s 5ms/step - loss: 0.5456 - accuracy: 0.7255 - val_loss: 0.6212 - val_accuracy: 0.6573\n",
      "Epoch 47/300\n",
      "62/62 [==============================] - 0s 5ms/step - loss: 0.5454 - accuracy: 0.7170 - val_loss: 0.6213 - val_accuracy: 0.6210\n",
      "Epoch 48/300\n",
      "62/62 [==============================] - 0s 5ms/step - loss: 0.5517 - accuracy: 0.7124 - val_loss: 0.6253 - val_accuracy: 0.6331\n",
      "Epoch 49/300\n",
      "62/62 [==============================] - 0s 6ms/step - loss: 0.5535 - accuracy: 0.7089 - val_loss: 0.6270 - val_accuracy: 0.6290\n",
      "Epoch 50/300\n",
      "62/62 [==============================] - 0s 5ms/step - loss: 0.5312 - accuracy: 0.7336 - val_loss: 0.6264 - val_accuracy: 0.6290\n",
      "Epoch 51/300\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.5424 - accuracy: 0.7164 - val_loss: 0.6133 - val_accuracy: 0.6492\n",
      "Epoch 52/300\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.5396 - accuracy: 0.7260 - val_loss: 0.6191 - val_accuracy: 0.6815\n",
      "Epoch 53/300\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.5385 - accuracy: 0.7119 - val_loss: 0.6170 - val_accuracy: 0.6452\n",
      "Epoch 54/300\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.5424 - accuracy: 0.7109 - val_loss: 0.6251 - val_accuracy: 0.6452\n",
      "Epoch 55/300\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.5321 - accuracy: 0.7301 - val_loss: 0.6262 - val_accuracy: 0.6210\n",
      "Epoch 56/300\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.5291 - accuracy: 0.7366 - val_loss: 0.6245 - val_accuracy: 0.6169\n",
      "Epoch 57/300\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.5361 - accuracy: 0.7281 - val_loss: 0.6441 - val_accuracy: 0.6250\n",
      "Epoch 58/300\n",
      "62/62 [==============================] - 0s 5ms/step - loss: 0.5393 - accuracy: 0.7255 - val_loss: 0.6400 - val_accuracy: 0.6129\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 59/300\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.5303 - accuracy: 0.7190 - val_loss: 0.6283 - val_accuracy: 0.6290\n",
      "Epoch 60/300\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.5382 - accuracy: 0.7200 - val_loss: 0.6247 - val_accuracy: 0.6210\n",
      "Epoch 61/300\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.5377 - accuracy: 0.7225 - val_loss: 0.6184 - val_accuracy: 0.6331\n",
      "Epoch 62/300\n",
      "62/62 [==============================] - 0s 6ms/step - loss: 0.5242 - accuracy: 0.7346 - val_loss: 0.6204 - val_accuracy: 0.6371\n",
      "Epoch 63/300\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.5339 - accuracy: 0.7331 - val_loss: 0.6421 - val_accuracy: 0.6331\n",
      "Epoch 64/300\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.5318 - accuracy: 0.7230 - val_loss: 0.6377 - val_accuracy: 0.6129\n",
      "Epoch 65/300\n",
      "62/62 [==============================] - 0s 6ms/step - loss: 0.5382 - accuracy: 0.7185 - val_loss: 0.6429 - val_accuracy: 0.6290\n",
      "Epoch 66/300\n",
      "62/62 [==============================] - 0s 6ms/step - loss: 0.5244 - accuracy: 0.7311 - val_loss: 0.6367 - val_accuracy: 0.6089\n",
      "Epoch 67/300\n",
      "62/62 [==============================] - 0s 5ms/step - loss: 0.5289 - accuracy: 0.7281 - val_loss: 0.6423 - val_accuracy: 0.5927\n",
      "Epoch 68/300\n",
      "62/62 [==============================] - 0s 5ms/step - loss: 0.5160 - accuracy: 0.7386 - val_loss: 0.6448 - val_accuracy: 0.6089\n",
      "Epoch 69/300\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.5239 - accuracy: 0.7270 - val_loss: 0.6279 - val_accuracy: 0.6250\n",
      "Epoch 70/300\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.5241 - accuracy: 0.7366 - val_loss: 0.6295 - val_accuracy: 0.6008\n",
      "Epoch 71/300\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.5221 - accuracy: 0.7427 - val_loss: 0.6418 - val_accuracy: 0.6048\n",
      "Epoch 72/300\n",
      "62/62 [==============================] - 0s 5ms/step - loss: 0.5211 - accuracy: 0.7361 - val_loss: 0.6290 - val_accuracy: 0.6048\n",
      "Epoch 73/300\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.5183 - accuracy: 0.7361 - val_loss: 0.6546 - val_accuracy: 0.6129\n",
      "Epoch 74/300\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.5120 - accuracy: 0.7442 - val_loss: 0.6575 - val_accuracy: 0.6048\n",
      "Epoch 75/300\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.5317 - accuracy: 0.7306 - val_loss: 0.6405 - val_accuracy: 0.6089\n",
      "Epoch 76/300\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.5220 - accuracy: 0.7225 - val_loss: 0.6507 - val_accuracy: 0.5887\n",
      "Epoch 77/300\n",
      "62/62 [==============================] - 0s 5ms/step - loss: 0.5125 - accuracy: 0.7457 - val_loss: 0.6514 - val_accuracy: 0.5968\n",
      "Epoch 78/300\n",
      "62/62 [==============================] - 0s 5ms/step - loss: 0.5242 - accuracy: 0.7260 - val_loss: 0.6341 - val_accuracy: 0.6573\n",
      "Epoch 79/300\n",
      "62/62 [==============================] - 0s 6ms/step - loss: 0.5127 - accuracy: 0.7457 - val_loss: 0.6306 - val_accuracy: 0.6169\n",
      "Epoch 80/300\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.5192 - accuracy: 0.7381 - val_loss: 0.6510 - val_accuracy: 0.6129\n",
      "Epoch 81/300\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.5346 - accuracy: 0.7291 - val_loss: 0.6447 - val_accuracy: 0.6169\n",
      "Epoch 82/300\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.5141 - accuracy: 0.7346 - val_loss: 0.6427 - val_accuracy: 0.5847\n",
      "Epoch 83/300\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.5117 - accuracy: 0.7381 - val_loss: 0.6349 - val_accuracy: 0.6210\n",
      "Epoch 84/300\n",
      "62/62 [==============================] - 0s 5ms/step - loss: 0.5191 - accuracy: 0.7457 - val_loss: 0.6389 - val_accuracy: 0.6331\n",
      "Epoch 85/300\n",
      "62/62 [==============================] - 0s 6ms/step - loss: 0.5200 - accuracy: 0.7326 - val_loss: 0.6531 - val_accuracy: 0.6210\n",
      "Epoch 86/300\n",
      "62/62 [==============================] - 0s 5ms/step - loss: 0.5205 - accuracy: 0.7296 - val_loss: 0.6531 - val_accuracy: 0.6250\n",
      "Epoch 87/300\n",
      "62/62 [==============================] - 0s 5ms/step - loss: 0.5231 - accuracy: 0.7296 - val_loss: 0.6496 - val_accuracy: 0.6331\n",
      "Epoch 88/300\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.5194 - accuracy: 0.7356 - val_loss: 0.6414 - val_accuracy: 0.6129\n",
      "Epoch 89/300\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.5133 - accuracy: 0.7361 - val_loss: 0.6399 - val_accuracy: 0.6290\n",
      "Epoch 90/300\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.5055 - accuracy: 0.7487 - val_loss: 0.6483 - val_accuracy: 0.6411\n",
      "Epoch 91/300\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.5096 - accuracy: 0.7477 - val_loss: 0.6442 - val_accuracy: 0.6210\n",
      "Epoch 92/300\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.5167 - accuracy: 0.7306 - val_loss: 0.6589 - val_accuracy: 0.6169\n",
      "Epoch 93/300\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.5134 - accuracy: 0.7376 - val_loss: 0.6609 - val_accuracy: 0.6250\n",
      "Epoch 94/300\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.5098 - accuracy: 0.7487 - val_loss: 0.6545 - val_accuracy: 0.6210\n",
      "Epoch 95/300\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.5003 - accuracy: 0.7412 - val_loss: 0.6596 - val_accuracy: 0.6129\n",
      "Epoch 96/300\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.4919 - accuracy: 0.7533 - val_loss: 0.6503 - val_accuracy: 0.6089\n",
      "Epoch 97/300\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.4929 - accuracy: 0.7573 - val_loss: 0.6663 - val_accuracy: 0.5968\n",
      "Epoch 98/300\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.5180 - accuracy: 0.7321 - val_loss: 0.6419 - val_accuracy: 0.6129\n",
      "Epoch 99/300\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.5098 - accuracy: 0.7508 - val_loss: 0.6453 - val_accuracy: 0.6331\n",
      "Epoch 100/300\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.4952 - accuracy: 0.7513 - val_loss: 0.6509 - val_accuracy: 0.6331\n",
      "Epoch 101/300\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.5084 - accuracy: 0.7513 - val_loss: 0.6566 - val_accuracy: 0.6250\n",
      "Epoch 102/300\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.4987 - accuracy: 0.7462 - val_loss: 0.6400 - val_accuracy: 0.6290\n",
      "Epoch 103/300\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.5029 - accuracy: 0.7518 - val_loss: 0.6346 - val_accuracy: 0.6452\n",
      "Epoch 104/300\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.5046 - accuracy: 0.7452 - val_loss: 0.6445 - val_accuracy: 0.6331\n",
      "Epoch 105/300\n",
      "62/62 [==============================] - 0s 5ms/step - loss: 0.4881 - accuracy: 0.7583 - val_loss: 0.6558 - val_accuracy: 0.6290\n",
      "Epoch 106/300\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.5029 - accuracy: 0.7376 - val_loss: 0.6532 - val_accuracy: 0.6290\n",
      "Epoch 107/300\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.5039 - accuracy: 0.7417 - val_loss: 0.6591 - val_accuracy: 0.6250\n",
      "Epoch 108/300\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.5128 - accuracy: 0.7477 - val_loss: 0.6527 - val_accuracy: 0.6290\n",
      "Epoch 109/300\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.5066 - accuracy: 0.7477 - val_loss: 0.6458 - val_accuracy: 0.6331\n",
      "Epoch 110/300\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.5006 - accuracy: 0.7341 - val_loss: 0.6465 - val_accuracy: 0.6210\n",
      "Epoch 111/300\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.4837 - accuracy: 0.7603 - val_loss: 0.6663 - val_accuracy: 0.6492\n",
      "Epoch 112/300\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.4891 - accuracy: 0.7558 - val_loss: 0.6457 - val_accuracy: 0.6250\n",
      "Epoch 113/300\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.5035 - accuracy: 0.7437 - val_loss: 0.6455 - val_accuracy: 0.6331\n",
      "Epoch 114/300\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.5055 - accuracy: 0.7381 - val_loss: 0.6481 - val_accuracy: 0.6452\n",
      "Epoch 115/300\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.4933 - accuracy: 0.7543 - val_loss: 0.6509 - val_accuracy: 0.6290\n",
      "Epoch 116/300\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.4858 - accuracy: 0.7578 - val_loss: 0.6449 - val_accuracy: 0.6532\n",
      "Epoch 117/300\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.5006 - accuracy: 0.7533 - val_loss: 0.6429 - val_accuracy: 0.6331\n",
      "Epoch 118/300\n",
      "62/62 [==============================] - 0s 5ms/step - loss: 0.5058 - accuracy: 0.7523 - val_loss: 0.6626 - val_accuracy: 0.6452\n",
      "Epoch 119/300\n",
      "62/62 [==============================] - 0s 6ms/step - loss: 0.4850 - accuracy: 0.7548 - val_loss: 0.6541 - val_accuracy: 0.6411\n",
      "Epoch 120/300\n",
      "62/62 [==============================] - 0s 5ms/step - loss: 0.4987 - accuracy: 0.7492 - val_loss: 0.6481 - val_accuracy: 0.6452\n",
      "Epoch 121/300\n",
      "62/62 [==============================] - 0s 5ms/step - loss: 0.5083 - accuracy: 0.7296 - val_loss: 0.6536 - val_accuracy: 0.6290\n",
      "Epoch 122/300\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.4995 - accuracy: 0.7492 - val_loss: 0.6542 - val_accuracy: 0.6250\n",
      "Epoch 123/300\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.5053 - accuracy: 0.7447 - val_loss: 0.6417 - val_accuracy: 0.6371\n",
      "Epoch 124/300\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.4903 - accuracy: 0.7503 - val_loss: 0.6489 - val_accuracy: 0.6331\n",
      "Epoch 125/300\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.4832 - accuracy: 0.7649 - val_loss: 0.6696 - val_accuracy: 0.6452\n",
      "Epoch 126/300\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.4945 - accuracy: 0.7558 - val_loss: 0.6553 - val_accuracy: 0.6411\n",
      "Epoch 127/300\n",
      "62/62 [==============================] - 0s 5ms/step - loss: 0.4907 - accuracy: 0.7694 - val_loss: 0.6388 - val_accuracy: 0.6452\n",
      "Epoch 128/300\n",
      "62/62 [==============================] - 0s 6ms/step - loss: 0.4939 - accuracy: 0.7392 - val_loss: 0.6457 - val_accuracy: 0.6371\n",
      "Epoch 129/300\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.4884 - accuracy: 0.7603 - val_loss: 0.6493 - val_accuracy: 0.6210\n",
      "Epoch 130/300\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.4972 - accuracy: 0.7523 - val_loss: 0.6432 - val_accuracy: 0.6290\n",
      "Epoch 131/300\n",
      "62/62 [==============================] - 0s 5ms/step - loss: 0.4984 - accuracy: 0.7397 - val_loss: 0.6447 - val_accuracy: 0.6250\n",
      "Epoch 132/300\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.4816 - accuracy: 0.7503 - val_loss: 0.6490 - val_accuracy: 0.6492\n",
      "Epoch 133/300\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.4968 - accuracy: 0.7497 - val_loss: 0.6569 - val_accuracy: 0.6331\n",
      "Epoch 134/300\n",
      "62/62 [==============================] - 0s 5ms/step - loss: 0.4887 - accuracy: 0.7543 - val_loss: 0.6640 - val_accuracy: 0.6290\n",
      "Epoch 135/300\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.4930 - accuracy: 0.7503 - val_loss: 0.6534 - val_accuracy: 0.6331\n",
      "Epoch 136/300\n",
      "62/62 [==============================] - 0s 8ms/step - loss: 0.4897 - accuracy: 0.7573 - val_loss: 0.6586 - val_accuracy: 0.6290\n",
      "Epoch 137/300\n",
      "62/62 [==============================] - 0s 5ms/step - loss: 0.4675 - accuracy: 0.7795 - val_loss: 0.6577 - val_accuracy: 0.6250\n",
      "Epoch 138/300\n",
      "62/62 [==============================] - 0s 5ms/step - loss: 0.4835 - accuracy: 0.7644 - val_loss: 0.6570 - val_accuracy: 0.6331\n",
      "Epoch 139/300\n",
      "62/62 [==============================] - 0s 5ms/step - loss: 0.4998 - accuracy: 0.7603 - val_loss: 0.6551 - val_accuracy: 0.6169\n",
      "Epoch 140/300\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.4793 - accuracy: 0.7649 - val_loss: 0.6722 - val_accuracy: 0.6250\n",
      "Epoch 141/300\n",
      "62/62 [==============================] - 0s 6ms/step - loss: 0.4731 - accuracy: 0.7719 - val_loss: 0.6643 - val_accuracy: 0.6371\n",
      "Epoch 142/300\n",
      "62/62 [==============================] - 0s 5ms/step - loss: 0.4796 - accuracy: 0.7593 - val_loss: 0.6786 - val_accuracy: 0.6290\n",
      "Epoch 143/300\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.4852 - accuracy: 0.7593 - val_loss: 0.6675 - val_accuracy: 0.6492\n",
      "Epoch 144/300\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.4929 - accuracy: 0.7558 - val_loss: 0.6649 - val_accuracy: 0.6331\n",
      "Epoch 145/300\n",
      "62/62 [==============================] - 0s 5ms/step - loss: 0.4721 - accuracy: 0.7735 - val_loss: 0.6647 - val_accuracy: 0.6411\n",
      "Epoch 146/300\n",
      "62/62 [==============================] - 0s 5ms/step - loss: 0.4806 - accuracy: 0.7669 - val_loss: 0.6663 - val_accuracy: 0.6411\n",
      "Epoch 147/300\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.4956 - accuracy: 0.7528 - val_loss: 0.6745 - val_accuracy: 0.6371\n",
      "Epoch 148/300\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.4901 - accuracy: 0.7503 - val_loss: 0.6648 - val_accuracy: 0.6290\n",
      "Epoch 149/300\n",
      "62/62 [==============================] - 0s 5ms/step - loss: 0.4903 - accuracy: 0.7568 - val_loss: 0.6924 - val_accuracy: 0.6250\n",
      "Epoch 150/300\n",
      "62/62 [==============================] - 0s 5ms/step - loss: 0.4768 - accuracy: 0.7583 - val_loss: 0.6714 - val_accuracy: 0.6371\n",
      "Epoch 151/300\n",
      "62/62 [==============================] - 0s 5ms/step - loss: 0.4829 - accuracy: 0.7538 - val_loss: 0.6731 - val_accuracy: 0.6371\n",
      "Epoch 152/300\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.4815 - accuracy: 0.7528 - val_loss: 0.6771 - val_accuracy: 0.6290\n",
      "Epoch 153/300\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.4807 - accuracy: 0.7624 - val_loss: 0.6640 - val_accuracy: 0.6371\n",
      "Epoch 154/300\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.4819 - accuracy: 0.7629 - val_loss: 0.6648 - val_accuracy: 0.6532\n",
      "Epoch 155/300\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.4831 - accuracy: 0.7518 - val_loss: 0.6769 - val_accuracy: 0.6331\n",
      "Epoch 156/300\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.4738 - accuracy: 0.7684 - val_loss: 0.6675 - val_accuracy: 0.6613\n",
      "Epoch 157/300\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.4746 - accuracy: 0.7639 - val_loss: 0.6618 - val_accuracy: 0.6452\n",
      "Epoch 158/300\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.4847 - accuracy: 0.7538 - val_loss: 0.6655 - val_accuracy: 0.6371\n",
      "Epoch 159/300\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.4941 - accuracy: 0.7573 - val_loss: 0.6527 - val_accuracy: 0.6573\n",
      "Epoch 160/300\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.4814 - accuracy: 0.7548 - val_loss: 0.6635 - val_accuracy: 0.6411\n",
      "Epoch 161/300\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.4849 - accuracy: 0.7548 - val_loss: 0.6570 - val_accuracy: 0.6411\n",
      "Epoch 162/300\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.4862 - accuracy: 0.7492 - val_loss: 0.6576 - val_accuracy: 0.6532\n",
      "Epoch 163/300\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.4850 - accuracy: 0.7634 - val_loss: 0.6459 - val_accuracy: 0.6613\n",
      "Epoch 164/300\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.4942 - accuracy: 0.7487 - val_loss: 0.6416 - val_accuracy: 0.6573\n",
      "Epoch 165/300\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.4750 - accuracy: 0.7694 - val_loss: 0.6606 - val_accuracy: 0.6371\n",
      "Epoch 166/300\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.4765 - accuracy: 0.7614 - val_loss: 0.6544 - val_accuracy: 0.6452\n",
      "Epoch 167/300\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.4721 - accuracy: 0.7603 - val_loss: 0.6661 - val_accuracy: 0.6290\n",
      "Epoch 168/300\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.4752 - accuracy: 0.7719 - val_loss: 0.6659 - val_accuracy: 0.6371\n",
      "Epoch 169/300\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.4839 - accuracy: 0.7467 - val_loss: 0.6586 - val_accuracy: 0.6452\n",
      "Epoch 170/300\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.4851 - accuracy: 0.7548 - val_loss: 0.6650 - val_accuracy: 0.6613\n",
      "Epoch 171/300\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.4714 - accuracy: 0.7704 - val_loss: 0.6619 - val_accuracy: 0.6532\n",
      "Epoch 172/300\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.4750 - accuracy: 0.7699 - val_loss: 0.6560 - val_accuracy: 0.6653\n",
      "Epoch 173/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "62/62 [==============================] - 0s 4ms/step - loss: 0.4711 - accuracy: 0.7619 - val_loss: 0.6583 - val_accuracy: 0.6613\n",
      "Epoch 174/300\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.4709 - accuracy: 0.7624 - val_loss: 0.6661 - val_accuracy: 0.6613\n",
      "Epoch 175/300\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.4726 - accuracy: 0.7669 - val_loss: 0.6551 - val_accuracy: 0.6532\n",
      "Epoch 176/300\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.4711 - accuracy: 0.7608 - val_loss: 0.6611 - val_accuracy: 0.6532\n",
      "Epoch 177/300\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.4692 - accuracy: 0.7709 - val_loss: 0.6712 - val_accuracy: 0.6371\n",
      "Epoch 178/300\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.4599 - accuracy: 0.7810 - val_loss: 0.6687 - val_accuracy: 0.6452\n",
      "Epoch 179/300\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.4724 - accuracy: 0.7669 - val_loss: 0.6642 - val_accuracy: 0.6331\n",
      "Epoch 180/300\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.4794 - accuracy: 0.7644 - val_loss: 0.6464 - val_accuracy: 0.6532\n",
      "Epoch 181/300\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.4740 - accuracy: 0.7619 - val_loss: 0.6614 - val_accuracy: 0.6452\n",
      "Epoch 182/300\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.4765 - accuracy: 0.7603 - val_loss: 0.6515 - val_accuracy: 0.6411\n",
      "Epoch 183/300\n",
      "62/62 [==============================] - 0s 5ms/step - loss: 0.4687 - accuracy: 0.7755 - val_loss: 0.6758 - val_accuracy: 0.6331\n",
      "Epoch 184/300\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.4755 - accuracy: 0.7593 - val_loss: 0.6655 - val_accuracy: 0.6331\n",
      "Epoch 185/300\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.4820 - accuracy: 0.7624 - val_loss: 0.6684 - val_accuracy: 0.6290\n",
      "Epoch 186/300\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.4614 - accuracy: 0.7906 - val_loss: 0.6686 - val_accuracy: 0.6532\n",
      "Epoch 187/300\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.4845 - accuracy: 0.7619 - val_loss: 0.6503 - val_accuracy: 0.6734\n",
      "Epoch 188/300\n",
      "62/62 [==============================] - 0s 5ms/step - loss: 0.4744 - accuracy: 0.7654 - val_loss: 0.6656 - val_accuracy: 0.6452\n",
      "Epoch 189/300\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.4623 - accuracy: 0.7871 - val_loss: 0.6785 - val_accuracy: 0.6492\n",
      "Epoch 190/300\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.4600 - accuracy: 0.7805 - val_loss: 0.6780 - val_accuracy: 0.6452\n",
      "Epoch 191/300\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.4562 - accuracy: 0.7765 - val_loss: 0.6680 - val_accuracy: 0.6452\n",
      "Epoch 192/300\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.4708 - accuracy: 0.7644 - val_loss: 0.6715 - val_accuracy: 0.6411\n",
      "Epoch 193/300\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.4655 - accuracy: 0.7704 - val_loss: 0.6855 - val_accuracy: 0.6411\n",
      "Epoch 194/300\n",
      "62/62 [==============================] - 0s 5ms/step - loss: 0.4740 - accuracy: 0.7654 - val_loss: 0.6832 - val_accuracy: 0.6371\n",
      "Epoch 195/300\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.4715 - accuracy: 0.7644 - val_loss: 0.6847 - val_accuracy: 0.6331\n",
      "Epoch 196/300\n",
      "62/62 [==============================] - 0s 5ms/step - loss: 0.4806 - accuracy: 0.7598 - val_loss: 0.6705 - val_accuracy: 0.6573\n",
      "Epoch 197/300\n",
      "62/62 [==============================] - 0s 6ms/step - loss: 0.4628 - accuracy: 0.7861 - val_loss: 0.6860 - val_accuracy: 0.6411\n",
      "Epoch 198/300\n",
      "62/62 [==============================] - 0s 6ms/step - loss: 0.4599 - accuracy: 0.7871 - val_loss: 0.6671 - val_accuracy: 0.6452\n",
      "Epoch 199/300\n",
      "62/62 [==============================] - 0s 5ms/step - loss: 0.4739 - accuracy: 0.7654 - val_loss: 0.6692 - val_accuracy: 0.6492\n",
      "Epoch 200/300\n",
      "62/62 [==============================] - 0s 6ms/step - loss: 0.4818 - accuracy: 0.7614 - val_loss: 0.6840 - val_accuracy: 0.6694\n",
      "Epoch 201/300\n",
      "62/62 [==============================] - 0s 5ms/step - loss: 0.4600 - accuracy: 0.7704 - val_loss: 0.6620 - val_accuracy: 0.6653\n",
      "Epoch 202/300\n",
      "62/62 [==============================] - 0s 6ms/step - loss: 0.4645 - accuracy: 0.7795 - val_loss: 0.6667 - val_accuracy: 0.6613\n",
      "Epoch 203/300\n",
      "62/62 [==============================] - 0s 5ms/step - loss: 0.4690 - accuracy: 0.7760 - val_loss: 0.6705 - val_accuracy: 0.6653\n",
      "Epoch 204/300\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.4565 - accuracy: 0.7815 - val_loss: 0.6817 - val_accuracy: 0.6492\n",
      "Epoch 205/300\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.4647 - accuracy: 0.7719 - val_loss: 0.6651 - val_accuracy: 0.6653\n",
      "Epoch 206/300\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.4795 - accuracy: 0.7679 - val_loss: 0.6739 - val_accuracy: 0.6573\n",
      "Epoch 207/300\n",
      "62/62 [==============================] - 0s 6ms/step - loss: 0.4789 - accuracy: 0.7704 - val_loss: 0.6685 - val_accuracy: 0.6492\n",
      "Epoch 208/300\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.4780 - accuracy: 0.7644 - val_loss: 0.6790 - val_accuracy: 0.6653\n",
      "Epoch 209/300\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.4684 - accuracy: 0.7704 - val_loss: 0.6600 - val_accuracy: 0.6613\n",
      "Epoch 210/300\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.4686 - accuracy: 0.7684 - val_loss: 0.6791 - val_accuracy: 0.6452\n",
      "Epoch 211/300\n",
      "62/62 [==============================] - 0s 6ms/step - loss: 0.4659 - accuracy: 0.7674 - val_loss: 0.6766 - val_accuracy: 0.6573\n",
      "Epoch 212/300\n",
      "62/62 [==============================] - 0s 6ms/step - loss: 0.4580 - accuracy: 0.7830 - val_loss: 0.6698 - val_accuracy: 0.6774\n",
      "Epoch 213/300\n",
      "62/62 [==============================] - 0s 6ms/step - loss: 0.4648 - accuracy: 0.7699 - val_loss: 0.6689 - val_accuracy: 0.6653\n",
      "Epoch 214/300\n",
      "62/62 [==============================] - 0s 5ms/step - loss: 0.4696 - accuracy: 0.7730 - val_loss: 0.6705 - val_accuracy: 0.6694\n",
      "Epoch 215/300\n",
      "62/62 [==============================] - 0s 6ms/step - loss: 0.4588 - accuracy: 0.7795 - val_loss: 0.6704 - val_accuracy: 0.6653\n",
      "Epoch 216/300\n",
      "62/62 [==============================] - 0s 5ms/step - loss: 0.4788 - accuracy: 0.7719 - val_loss: 0.6625 - val_accuracy: 0.6694\n",
      "Epoch 217/300\n",
      "62/62 [==============================] - 0s 5ms/step - loss: 0.4629 - accuracy: 0.7830 - val_loss: 0.6703 - val_accuracy: 0.6734\n",
      "Epoch 218/300\n",
      "62/62 [==============================] - 0s 5ms/step - loss: 0.4332 - accuracy: 0.7997 - val_loss: 0.6796 - val_accuracy: 0.6452\n",
      "Epoch 219/300\n",
      "62/62 [==============================] - 0s 6ms/step - loss: 0.4721 - accuracy: 0.7689 - val_loss: 0.6733 - val_accuracy: 0.6492\n",
      "Epoch 220/300\n",
      "62/62 [==============================] - 0s 5ms/step - loss: 0.4619 - accuracy: 0.7795 - val_loss: 0.6825 - val_accuracy: 0.6411\n",
      "Epoch 221/300\n",
      "62/62 [==============================] - 0s 5ms/step - loss: 0.4565 - accuracy: 0.7770 - val_loss: 0.6856 - val_accuracy: 0.6573\n",
      "Epoch 222/300\n",
      "62/62 [==============================] - 0s 5ms/step - loss: 0.4536 - accuracy: 0.7725 - val_loss: 0.6808 - val_accuracy: 0.6452\n",
      "Epoch 223/300\n",
      "62/62 [==============================] - 0s 6ms/step - loss: 0.4579 - accuracy: 0.7851 - val_loss: 0.6889 - val_accuracy: 0.6613\n",
      "Epoch 224/300\n",
      "62/62 [==============================] - 0s 5ms/step - loss: 0.4740 - accuracy: 0.7694 - val_loss: 0.6725 - val_accuracy: 0.6653\n",
      "Epoch 225/300\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.4535 - accuracy: 0.7805 - val_loss: 0.6735 - val_accuracy: 0.6613\n",
      "Epoch 226/300\n",
      "62/62 [==============================] - 0s 5ms/step - loss: 0.4457 - accuracy: 0.7825 - val_loss: 0.6897 - val_accuracy: 0.6331\n",
      "Epoch 227/300\n",
      "62/62 [==============================] - 0s 6ms/step - loss: 0.4637 - accuracy: 0.7740 - val_loss: 0.6897 - val_accuracy: 0.6573\n",
      "Epoch 228/300\n",
      "62/62 [==============================] - 0s 5ms/step - loss: 0.4760 - accuracy: 0.7704 - val_loss: 0.6701 - val_accuracy: 0.6452\n",
      "Epoch 229/300\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.4592 - accuracy: 0.7780 - val_loss: 0.6764 - val_accuracy: 0.6573\n",
      "Epoch 230/300\n",
      "62/62 [==============================] - 0s 6ms/step - loss: 0.4614 - accuracy: 0.7775 - val_loss: 0.6760 - val_accuracy: 0.6452\n",
      "Epoch 231/300\n",
      "62/62 [==============================] - 0s 5ms/step - loss: 0.4577 - accuracy: 0.7876 - val_loss: 0.6878 - val_accuracy: 0.6250\n",
      "Epoch 232/300\n",
      "62/62 [==============================] - 0s 5ms/step - loss: 0.4629 - accuracy: 0.7750 - val_loss: 0.6844 - val_accuracy: 0.6613\n",
      "Epoch 233/300\n",
      "62/62 [==============================] - 0s 5ms/step - loss: 0.4596 - accuracy: 0.7740 - val_loss: 0.6986 - val_accuracy: 0.6411\n",
      "Epoch 234/300\n",
      "62/62 [==============================] - 0s 6ms/step - loss: 0.4654 - accuracy: 0.7704 - val_loss: 0.6743 - val_accuracy: 0.6694\n",
      "Epoch 235/300\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.4580 - accuracy: 0.7725 - val_loss: 0.6888 - val_accuracy: 0.6452\n",
      "Epoch 236/300\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.4625 - accuracy: 0.7830 - val_loss: 0.6891 - val_accuracy: 0.6532\n",
      "Epoch 237/300\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.4725 - accuracy: 0.7689 - val_loss: 0.6864 - val_accuracy: 0.6613\n",
      "Epoch 238/300\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.4659 - accuracy: 0.7745 - val_loss: 0.6725 - val_accuracy: 0.6613\n",
      "Epoch 239/300\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.4664 - accuracy: 0.7760 - val_loss: 0.6737 - val_accuracy: 0.6532\n",
      "Epoch 240/300\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.4631 - accuracy: 0.7704 - val_loss: 0.6689 - val_accuracy: 0.6532\n",
      "Epoch 241/300\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.4615 - accuracy: 0.7709 - val_loss: 0.6577 - val_accuracy: 0.6573\n",
      "Epoch 242/300\n",
      "62/62 [==============================] - 0s 6ms/step - loss: 0.4559 - accuracy: 0.7805 - val_loss: 0.6694 - val_accuracy: 0.6573\n",
      "Epoch 243/300\n",
      "62/62 [==============================] - 0s 5ms/step - loss: 0.4671 - accuracy: 0.7704 - val_loss: 0.6592 - val_accuracy: 0.6855\n",
      "Epoch 244/300\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.4504 - accuracy: 0.7674 - val_loss: 0.6516 - val_accuracy: 0.6613\n",
      "Epoch 245/300\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.4576 - accuracy: 0.7765 - val_loss: 0.6732 - val_accuracy: 0.6653\n",
      "Epoch 246/300\n",
      "62/62 [==============================] - 0s 6ms/step - loss: 0.4549 - accuracy: 0.7891 - val_loss: 0.6773 - val_accuracy: 0.6492\n",
      "Epoch 247/300\n",
      "62/62 [==============================] - 0s 5ms/step - loss: 0.4455 - accuracy: 0.7800 - val_loss: 0.6766 - val_accuracy: 0.6371\n",
      "Epoch 248/300\n",
      "62/62 [==============================] - 0s 6ms/step - loss: 0.4591 - accuracy: 0.7780 - val_loss: 0.6631 - val_accuracy: 0.6573\n",
      "Epoch 249/300\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.4464 - accuracy: 0.7846 - val_loss: 0.6680 - val_accuracy: 0.6573\n",
      "Epoch 250/300\n",
      "62/62 [==============================] - 0s 6ms/step - loss: 0.4543 - accuracy: 0.7745 - val_loss: 0.6695 - val_accuracy: 0.6532\n",
      "Epoch 251/300\n",
      "62/62 [==============================] - 0s 6ms/step - loss: 0.4516 - accuracy: 0.7901 - val_loss: 0.6707 - val_accuracy: 0.6532\n",
      "Epoch 252/300\n",
      "62/62 [==============================] - 0s 5ms/step - loss: 0.4590 - accuracy: 0.7795 - val_loss: 0.6726 - val_accuracy: 0.6573\n",
      "Epoch 253/300\n",
      "62/62 [==============================] - 0s 5ms/step - loss: 0.4522 - accuracy: 0.7851 - val_loss: 0.6802 - val_accuracy: 0.6573\n",
      "Epoch 254/300\n",
      "62/62 [==============================] - 0s 6ms/step - loss: 0.4454 - accuracy: 0.7805 - val_loss: 0.6750 - val_accuracy: 0.6613\n",
      "Epoch 255/300\n",
      "62/62 [==============================] - 0s 5ms/step - loss: 0.4571 - accuracy: 0.7851 - val_loss: 0.6689 - val_accuracy: 0.6532\n",
      "Epoch 256/300\n",
      "62/62 [==============================] - 0s 5ms/step - loss: 0.4701 - accuracy: 0.7603 - val_loss: 0.6845 - val_accuracy: 0.6613\n",
      "Epoch 257/300\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.4658 - accuracy: 0.7674 - val_loss: 0.6801 - val_accuracy: 0.6411\n",
      "Epoch 258/300\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.4533 - accuracy: 0.7805 - val_loss: 0.6795 - val_accuracy: 0.6532\n",
      "Epoch 259/300\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.4507 - accuracy: 0.7775 - val_loss: 0.6706 - val_accuracy: 0.6532\n",
      "Epoch 260/300\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.4416 - accuracy: 0.7891 - val_loss: 0.6982 - val_accuracy: 0.6492\n",
      "Epoch 261/300\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.4559 - accuracy: 0.7810 - val_loss: 0.7000 - val_accuracy: 0.6331\n",
      "Epoch 262/300\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.4608 - accuracy: 0.7810 - val_loss: 0.6873 - val_accuracy: 0.6532\n",
      "Epoch 263/300\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.4625 - accuracy: 0.7634 - val_loss: 0.6791 - val_accuracy: 0.6532\n",
      "Epoch 264/300\n",
      "62/62 [==============================] - 0s 5ms/step - loss: 0.4700 - accuracy: 0.7674 - val_loss: 0.6687 - val_accuracy: 0.6653\n",
      "Epoch 265/300\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.4449 - accuracy: 0.7825 - val_loss: 0.6720 - val_accuracy: 0.6492\n",
      "Epoch 266/300\n",
      "62/62 [==============================] - 0s 5ms/step - loss: 0.4533 - accuracy: 0.7820 - val_loss: 0.6896 - val_accuracy: 0.6573\n",
      "Epoch 267/300\n",
      "62/62 [==============================] - 0s 5ms/step - loss: 0.4571 - accuracy: 0.7841 - val_loss: 0.6743 - val_accuracy: 0.6653\n",
      "Epoch 268/300\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.4506 - accuracy: 0.7815 - val_loss: 0.6765 - val_accuracy: 0.6613\n",
      "Epoch 269/300\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.4662 - accuracy: 0.7800 - val_loss: 0.6809 - val_accuracy: 0.6613\n",
      "Epoch 270/300\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.4632 - accuracy: 0.7810 - val_loss: 0.6874 - val_accuracy: 0.6411\n",
      "Epoch 271/300\n",
      "62/62 [==============================] - 0s 5ms/step - loss: 0.4562 - accuracy: 0.7760 - val_loss: 0.6832 - val_accuracy: 0.6290\n",
      "Epoch 272/300\n",
      "62/62 [==============================] - 0s 5ms/step - loss: 0.4762 - accuracy: 0.7654 - val_loss: 0.6807 - val_accuracy: 0.6492\n",
      "Epoch 273/300\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.4522 - accuracy: 0.7830 - val_loss: 0.6959 - val_accuracy: 0.6371\n",
      "Epoch 274/300\n",
      "62/62 [==============================] - 0s 5ms/step - loss: 0.4558 - accuracy: 0.7745 - val_loss: 0.6886 - val_accuracy: 0.6452\n",
      "Epoch 275/300\n",
      "62/62 [==============================] - 0s 5ms/step - loss: 0.4642 - accuracy: 0.7750 - val_loss: 0.6915 - val_accuracy: 0.6573\n",
      "Epoch 276/300\n",
      "62/62 [==============================] - 0s 7ms/step - loss: 0.4515 - accuracy: 0.7775 - val_loss: 0.6917 - val_accuracy: 0.6573\n",
      "Epoch 277/300\n",
      "62/62 [==============================] - 1s 8ms/step - loss: 0.4630 - accuracy: 0.7654 - val_loss: 0.7148 - val_accuracy: 0.6411\n",
      "Epoch 278/300\n",
      "62/62 [==============================] - 0s 6ms/step - loss: 0.4673 - accuracy: 0.7704 - val_loss: 0.6729 - val_accuracy: 0.6532\n",
      "Epoch 279/300\n",
      "62/62 [==============================] - 0s 5ms/step - loss: 0.4476 - accuracy: 0.7886 - val_loss: 0.6779 - val_accuracy: 0.6371\n",
      "Epoch 280/300\n",
      "62/62 [==============================] - 0s 5ms/step - loss: 0.4558 - accuracy: 0.7891 - val_loss: 0.6835 - val_accuracy: 0.6452\n",
      "Epoch 281/300\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.4717 - accuracy: 0.7735 - val_loss: 0.6918 - val_accuracy: 0.6532\n",
      "Epoch 282/300\n",
      "62/62 [==============================] - 0s 5ms/step - loss: 0.4494 - accuracy: 0.7765 - val_loss: 0.6926 - val_accuracy: 0.6452\n",
      "Epoch 283/300\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.4525 - accuracy: 0.7911 - val_loss: 0.6830 - val_accuracy: 0.6411\n",
      "Epoch 284/300\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.4613 - accuracy: 0.7704 - val_loss: 0.6928 - val_accuracy: 0.6411\n",
      "Epoch 285/300\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.4407 - accuracy: 0.7886 - val_loss: 0.6929 - val_accuracy: 0.6371\n",
      "Epoch 286/300\n",
      "62/62 [==============================] - 0s 5ms/step - loss: 0.4473 - accuracy: 0.7841 - val_loss: 0.6726 - val_accuracy: 0.6411\n",
      "Epoch 287/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "62/62 [==============================] - 0s 4ms/step - loss: 0.4454 - accuracy: 0.7911 - val_loss: 0.6884 - val_accuracy: 0.6532\n",
      "Epoch 288/300\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.4594 - accuracy: 0.7810 - val_loss: 0.7020 - val_accuracy: 0.6492\n",
      "Epoch 289/300\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.4562 - accuracy: 0.7780 - val_loss: 0.6972 - val_accuracy: 0.6452\n",
      "Epoch 290/300\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.4513 - accuracy: 0.7820 - val_loss: 0.6809 - val_accuracy: 0.6452\n",
      "Epoch 291/300\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.4479 - accuracy: 0.7785 - val_loss: 0.6798 - val_accuracy: 0.6653\n",
      "Epoch 292/300\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.4517 - accuracy: 0.7775 - val_loss: 0.6887 - val_accuracy: 0.6573\n",
      "Epoch 293/300\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.4459 - accuracy: 0.7941 - val_loss: 0.6893 - val_accuracy: 0.6573\n",
      "Epoch 294/300\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.4561 - accuracy: 0.7947 - val_loss: 0.7247 - val_accuracy: 0.6331\n",
      "Epoch 295/300\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.4517 - accuracy: 0.7851 - val_loss: 0.7087 - val_accuracy: 0.6532\n",
      "Epoch 296/300\n",
      "62/62 [==============================] - 0s 5ms/step - loss: 0.4582 - accuracy: 0.7679 - val_loss: 0.6931 - val_accuracy: 0.6452\n",
      "Epoch 297/300\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.4410 - accuracy: 0.7957 - val_loss: 0.6857 - val_accuracy: 0.6532\n",
      "Epoch 298/300\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.4485 - accuracy: 0.7785 - val_loss: 0.6978 - val_accuracy: 0.6613\n",
      "Epoch 299/300\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.4539 - accuracy: 0.7750 - val_loss: 0.6935 - val_accuracy: 0.6653\n",
      "Epoch 300/300\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.4499 - accuracy: 0.7856 - val_loss: 0.6996 - val_accuracy: 0.6573\n"
     ]
    }
   ],
   "source": [
    "tf.random.set_seed(0)\n",
    "\n",
    "history = model.fit(X_train,\n",
    "                    Y_train,\n",
    "                    epochs=300,\n",
    "                    batch_size=32,\n",
    "                    validation_data=(X_val, Y_val),\n",
    "                   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "a2c0bb60",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-29T13:49:26.094867Z",
     "start_time": "2023-01-29T13:49:25.939317Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 0s 5ms/step - loss: 0.7022 - accuracy: 0.6573\n",
      "Test Error 0.7022398114204407\n",
      "Test accuracy 0.6572580933570862\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(X_test, Y_test, verbose=1)\n",
    "\n",
    "print(\"Test Error\", score[0])\n",
    "print(\"Test accuracy\", score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "d0987d4a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-29T13:56:42.281187Z",
     "start_time": "2023-01-29T13:56:40.161722Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[98 25]\n",
      " [45 80]]\n",
      "Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.69      0.80      0.74       123\n",
      "         1.0       0.76      0.64      0.70       125\n",
      "\n",
      "    accuracy                           0.72       248\n",
      "   macro avg       0.72      0.72      0.72       248\n",
      "weighted avg       0.72      0.72      0.72       248\n",
      "\n"
     ]
    }
   ],
   "source": [
    "xgb_clf_final = XGBClassifier(n_estimators=250, max_depth=17, min_child_weight=1,learning_rate= 0.05)\n",
    "xgb_clf_final.fit(X_train, Y_train)\n",
    "predictions_test = xgb_clf_final.predict(X_test)\n",
    "\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(Y_test, predictions_test))\n",
    "\n",
    "print(\"Classification Report\")\n",
    "print(classification_report(Y_test, predictions_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "6f8dd174",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-29T13:59:07.698599Z",
     "start_time": "2023-01-29T13:59:07.666652Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[48 15]\n",
      " [24 37]]\n",
      "Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.67      0.76      0.71        63\n",
      "         1.0       0.71      0.61      0.65        61\n",
      "\n",
      "    accuracy                           0.69       124\n",
      "   macro avg       0.69      0.68      0.68       124\n",
      "weighted avg       0.69      0.69      0.68       124\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions_val = xgb_clf_final.predict(X_val)\n",
    "\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(Y_val, predictions_val))\n",
    "\n",
    "print(\"Classification Report\")\n",
    "print(classification_report(Y_val, predictions_val))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea69174a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": true,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
